{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Keras RNN.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"metadata":{"id":"fWwC3arcpQO5","colab_type":"code","outputId":"c808342b-aa4d-4892-8712-9175c1ed3477","executionInfo":{"status":"ok","timestamp":1548361722551,"user_tz":-60,"elapsed":4476,"user":{"displayName":"Gilles Vandewiele","photoUrl":"","userId":"04070140729205161481"}},"colab":{"base_uri":"https://localhost:8080/","height":164}},"cell_type":"code","source":["!pip install keras"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: keras in /usr/local/lib/python3.6/dist-packages (2.2.4)\n","Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from keras) (1.1.0)\n","Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from keras) (1.11.0)\n","Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from keras) (1.0.6)\n","Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from keras) (1.0.5)\n","Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras) (2.8.0)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from keras) (3.13)\n","Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.6/dist-packages (from keras) (1.14.6)\n"],"name":"stdout"}]},{"metadata":{"id":"Mfnn3dhIpRf2","colab_type":"code","outputId":"95ef8f90-9d49-4db0-86bc-ae66c4751fd2","executionInfo":{"status":"ok","timestamp":1548361726274,"user_tz":-60,"elapsed":8146,"user":{"displayName":"Gilles Vandewiele","photoUrl":"","userId":"04070140729205161481"}},"colab":{"base_uri":"https://localhost:8080/","height":35}},"cell_type":"code","source":["# The essentials\n","import pandas as pd\n","import numpy as np\n","\n","# Plotting\n","%matplotlib inline\n","import matplotlib.pyplot as plt\n","from IPython.display import clear_output\n","\n","# Progress bars\n","from tqdm import tqdm_notebook\n","\n","import pickle\n","from time import time\n","\n","from keras import models, layers, optimizers, callbacks\n","\n","# Access our Google Drive\n","from google.colab import drive"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Using TensorFlow backend.\n"],"name":"stderr"}]},{"metadata":{"id":"pZx3yLBk0fPQ","colab_type":"code","colab":{}},"cell_type":"code","source":["import tensorflow as tf\n","import keras\n","\n","config = tf.ConfigProto( device_count = {'GPU': 1 , 'CPU': 56} ) \n","sess = tf.Session(config=config) \n","keras.backend.set_session(sess)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"kS3W05UYpUFT","colab_type":"code","outputId":"4dd83aa7-67ab-4489-bed4-e7f7d5e7e383","executionInfo":{"status":"ok","timestamp":1548361750954,"user_tz":-60,"elapsed":32777,"user":{"displayName":"Gilles Vandewiele","photoUrl":"","userId":"04070140729205161481"}},"colab":{"base_uri":"https://localhost:8080/","height":4076}},"cell_type":"code","source":["drive.mount('/content/drive', force_remount=True)\n","!ls \"/content/drive/My Drive/Rinse Over Run\""],"execution_count":4,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n","all_train_preds_per_phase.p\n","baseline_features_with_preds_per_phase.csv\n","baseline_model_per_nunique_phases.csv\n","predictions_machine_405.csv\n","test_features_14.csv\n","test_features_15.csv\n","test_features_1.csv\n","test_features_2.csv\n","test_features_3.csv\n","test_features_6.csv\n","test_features_7.csv\n","test_features_8.csv\n","test_features_per_phase_14.csv\n","test_features_per_phase_15.csv\n","test_features_per_phase_1.csv\n","test_features_per_phase_2.csv\n","test_features_per_phase_3.csv\n","test_features_per_phase_6.csv\n","test_features_per_phase_7.csv\n","test_features_per_phase_8.csv\n","test_preds_per_phase.p\n","test_values.csv\n","train_features_14.csv\n","train_features_15.csv\n","train_features_1.csv\n","train_features_2.csv\n","train_features_3.csv\n","train_features_6.csv\n","train_features_7.csv\n","train_features_8.csv\n","train_features_adv_14.csv\n","train_features_adv_15.csv\n","train_features_adv_1.csv\n","train_features_adv_2.csv\n","train_features_adv_3.csv\n","train_features_adv_6.csv\n","train_features_adv_7.csv\n","train_features_adv_8.csv\n","train_features_per_phase_14.csv\n","train_features_per_phase_15.csv\n","train_features_per_phase_1.csv\n","train_features_per_phase_2.csv\n","train_features_per_phase_3.csv\n","train_features_per_phase_6.csv\n","train_features_per_phase_7.csv\n","train_features_per_phase_8.csv\n","train_labels.csv\n","train_preds_per_phase.p\n","train_values.csv\n","tsfresh_all_per_phase_combination_adv.csv\n","tsfresh_all_per_phase_combination.csv\n","tsfresh_features_14.csv\n","tsfresh_features_15.csv\n","tsfresh_features_1.csv\n","tsfresh_features_2.csv\n","tsfresh_features_3.csv\n","tsfresh_features_6.csv\n","tsfresh_features_7.csv\n","tsfresh_features_8.csv\n","tsfresh_features_object_low_level_14.csv\n","tsfresh_features_object_low_level_1.csv\n","tsfresh_features_object_low_level_2.csv\n","tsfresh_features_object_low_level_3.csv\n","tsfresh_features_object_low_level_6.csv\n","tsfresh_features_object_low_level_7.csv\n","tsfresh_features_return_acid_14.csv\n","tsfresh_features_return_acid_1.csv\n","tsfresh_features_return_acid_2.csv\n","tsfresh_features_return_acid_3.csv\n","tsfresh_features_return_acid_6.csv\n","tsfresh_features_return_acid_7.csv\n","tsfresh_features_return_caustic_14.csv\n","tsfresh_features_return_caustic_1.csv\n","tsfresh_features_return_caustic_2.csv\n","tsfresh_features_return_caustic_3.csv\n","tsfresh_features_return_caustic_6.csv\n","tsfresh_features_return_caustic_7.csv\n","tsfresh_features_return_conductivity_14.csv\n","tsfresh_features_return_conductivity_1.csv\n","tsfresh_features_return_conductivity_2.csv\n","tsfresh_features_return_conductivity_3.csv\n","tsfresh_features_return_conductivity_6.csv\n","tsfresh_features_return_conductivity_7.csv\n","tsfresh_features_return_drain_14.csv\n","tsfresh_features_return_drain_1.csv\n","tsfresh_features_return_drain_2.csv\n","tsfresh_features_return_drain_3.csv\n","tsfresh_features_return_drain_6.csv\n","tsfresh_features_return_drain_7.csv\n","tsfresh_features_return_flow_14.csv\n","tsfresh_features_return_flow_1.csv\n","tsfresh_features_return_flow_2.csv\n","tsfresh_features_return_flow_3.csv\n","tsfresh_features_return_flow_6.csv\n","tsfresh_features_return_flow_7.csv\n","tsfresh_features_return_recovery_water_14.csv\n","tsfresh_features_return_recovery_water_1.csv\n","tsfresh_features_return_recovery_water_2.csv\n","tsfresh_features_return_recovery_water_3.csv\n","tsfresh_features_return_recovery_water_6.csv\n","tsfresh_features_return_recovery_water_7.csv\n","tsfresh_features_return_temperature_14.csv\n","tsfresh_features_return_temperature_1.csv\n","tsfresh_features_return_temperature_2.csv\n","tsfresh_features_return_temperature_3.csv\n","tsfresh_features_return_temperature_6.csv\n","tsfresh_features_return_temperature_7.csv\n","tsfresh_features_return_turbidity_14.csv\n","tsfresh_features_return_turbidity_1.csv\n","tsfresh_features_return_turbidity_2.csv\n","tsfresh_features_return_turbidity_3.csv\n","tsfresh_features_return_turbidity_6.csv\n","tsfresh_features_return_turbidity_7.csv\n","tsfresh_features_supply_acid_14.csv\n","tsfresh_features_supply_acid_1.csv\n","tsfresh_features_supply_acid_2.csv\n","tsfresh_features_supply_acid_3.csv\n","tsfresh_features_supply_acid_6.csv\n","tsfresh_features_supply_acid_7.csv\n","tsfresh_features_supply_caustic_14.csv\n","tsfresh_features_supply_caustic_1.csv\n","tsfresh_features_supply_caustic_2.csv\n","tsfresh_features_supply_caustic_3.csv\n","tsfresh_features_supply_caustic_6.csv\n","tsfresh_features_supply_caustic_7.csv\n","tsfresh_features_supply_clean_water_14.csv\n","tsfresh_features_supply_clean_water_1.csv\n","tsfresh_features_supply_clean_water_2.csv\n","tsfresh_features_supply_clean_water_3.csv\n","tsfresh_features_supply_clean_water_6.csv\n","tsfresh_features_supply_clean_water_7.csv\n","tsfresh_features_supply_flow_14.csv\n","tsfresh_features_supply_flow_1.csv\n","tsfresh_features_supply_flow_2.csv\n","tsfresh_features_supply_flow_3.csv\n","tsfresh_features_supply_flow_6.csv\n","tsfresh_features_supply_flow_7.csv\n","tsfresh_features_supply_pre_rinse_14.csv\n","tsfresh_features_supply_pre_rinse_1.csv\n","tsfresh_features_supply_pre_rinse_2.csv\n","tsfresh_features_supply_pre_rinse_3.csv\n","tsfresh_features_supply_pre_rinse_6.csv\n","tsfresh_features_supply_pre_rinse_7.csv\n","tsfresh_features_supply_pressure_14.csv\n","tsfresh_features_supply_pressure_1.csv\n","tsfresh_features_supply_pressure_2.csv\n","tsfresh_features_supply_pressure_3.csv\n","tsfresh_features_supply_pressure_6.csv\n","tsfresh_features_supply_pressure_7.csv\n","tsfresh_features_supply_pump_14.csv\n","tsfresh_features_supply_pump_1.csv\n","tsfresh_features_supply_pump_2.csv\n","tsfresh_features_supply_pump_3.csv\n","tsfresh_features_supply_pump_6.csv\n","tsfresh_features_supply_pump_7.csv\n","tsfresh_features_tank_concentration_acid_14.csv\n","tsfresh_features_tank_concentration_acid_1.csv\n","tsfresh_features_tank_concentration_acid_2.csv\n","tsfresh_features_tank_concentration_acid_3.csv\n","tsfresh_features_tank_concentration_acid_6.csv\n","tsfresh_features_tank_concentration_acid_7.csv\n","tsfresh_features_tank_concentration_caustic_14.csv\n","tsfresh_features_tank_concentration_caustic_1.csv\n","tsfresh_features_tank_concentration_caustic_2.csv\n","tsfresh_features_tank_concentration_caustic_3.csv\n","tsfresh_features_tank_concentration_caustic_6.csv\n","tsfresh_features_tank_concentration_caustic_7.csv\n","tsfresh_features_tank_level_acid_14.csv\n","tsfresh_features_tank_level_acid_1.csv\n","tsfresh_features_tank_level_acid_2.csv\n","tsfresh_features_tank_level_acid_3.csv\n","tsfresh_features_tank_level_acid_6.csv\n","tsfresh_features_tank_level_acid_7.csv\n","tsfresh_features_tank_level_caustic_14.csv\n","tsfresh_features_tank_level_caustic_1.csv\n","tsfresh_features_tank_level_caustic_2.csv\n","tsfresh_features_tank_level_caustic_3.csv\n","tsfresh_features_tank_level_caustic_6.csv\n","tsfresh_features_tank_level_caustic_7.csv\n","tsfresh_features_tank_level_clean_water_14.csv\n","tsfresh_features_tank_level_clean_water_1.csv\n","tsfresh_features_tank_level_clean_water_2.csv\n","tsfresh_features_tank_level_clean_water_3.csv\n","tsfresh_features_tank_level_clean_water_6.csv\n","tsfresh_features_tank_level_clean_water_7.csv\n","tsfresh_features_tank_level_pre_rinse_14.csv\n","tsfresh_features_tank_level_pre_rinse_1.csv\n","tsfresh_features_tank_level_pre_rinse_2.csv\n","tsfresh_features_tank_level_pre_rinse_3.csv\n","tsfresh_features_tank_level_pre_rinse_6.csv\n","tsfresh_features_tank_level_pre_rinse_7.csv\n","tsfresh_features_tank_temperature_acid_14.csv\n","tsfresh_features_tank_temperature_acid_1.csv\n","tsfresh_features_tank_temperature_acid_2.csv\n","tsfresh_features_tank_temperature_acid_3.csv\n","tsfresh_features_tank_temperature_acid_6.csv\n","tsfresh_features_tank_temperature_acid_7.csv\n","tsfresh_features_tank_temperature_caustic_14.csv\n","tsfresh_features_tank_temperature_caustic_1.csv\n","tsfresh_features_tank_temperature_caustic_2.csv\n","tsfresh_features_tank_temperature_caustic_3.csv\n","tsfresh_features_tank_temperature_caustic_6.csv\n","tsfresh_features_tank_temperature_caustic_7.csv\n","tsfresh_features_tank_temperature_pre_rinse_14.csv\n","tsfresh_features_tank_temperature_pre_rinse_1.csv\n","tsfresh_features_tank_temperature_pre_rinse_2.csv\n","tsfresh_features_tank_temperature_pre_rinse_3.csv\n","tsfresh_features_tank_temperature_pre_rinse_6.csv\n","tsfresh_features_tank_temperature_pre_rinse_7.csv\n","tsfresh_mix_per_phase_combination_adv.csv\n","tsfresh_none_per_phase_combination_adv.csv\n","val_features_adv_14.csv\n","val_features_adv_15.csv\n","val_features_adv_1.csv\n","val_features_adv_2.csv\n","val_features_adv_3.csv\n","val_features_adv_6.csv\n","val_features_adv_7.csv\n","val_features_adv_8.csv\n","val_preds_per_phase.p\n"],"name":"stdout"}]},{"metadata":{"id":"wa6ql0B6pXIV","colab_type":"code","colab":{}},"cell_type":"code","source":["def filter_data(raw_data, processes, phases, columns):\n","    filtered_data = raw_data[(raw_data['process_id'].isin(processes)) & \n","                             (raw_data['phase'].isin(phases))][['process_id', 'timestamp'] + columns]\n","    filtered_data = filtered_data.reset_index(drop=True)\n","    return filtered_data\n","  \n","def resample_fixed(df, n_new):\n","    n_old, m = df.values.shape\n","    mat_old = df.values\n","    mat_new = np.zeros((n_new, m))\n","    x_old = np.linspace(df.index.min(), df.index.max(), n_old)\n","    x_new = np.linspace(df.index.min(), df.index.max(), n_new)\n","\n","    for j in range(m):\n","        y_old = mat_old[:, j]\n","        y_new = np.interp(x_new, x_old, y_old)\n","        mat_new[:, j] = y_new\n","\n","    return pd.DataFrame(mat_new, index=x_new, columns=df.columns)\n","\n","def get_time_series(data, processes, cols, mask=0, max_len=1000, masking=False):\n","    all_ts_values = []\n","    \n","    for col in ts_cols:\n","      data[col] = data[col].astype(float)\n","      data[col] = (data[col] - data[col].min()) / (data[col].max() - data[col].min())\n","      \n","    for ix, process in enumerate(processes):\n","        filtered_data = data[data['process_id'] == process]\n","        filtered_data = filtered_data.sort_values(by='timestamp')\n","        filtered_data = filtered_data.reset_index(drop=True)\n","        filtered_data = filtered_data[cols].astype(float)\n","        for col in filtered_data.columns:\n","          if min(filtered_data[col]) < 0:\n","            filtered_data[col] += (abs(min(filtered_data[col])) + 1)\n","        if len(filtered_data) > max_len:\n","          filtered_data['ix'] = filtered_data.index // (len(filtered_data)/max_len)\n","          filtered_data = filtered_data.groupby('ix').mean()\n","          ts_values = filtered_data[ts_cols].values\n","        elif not masking and len(filtered_data) < max_len:\n","          ts_values = resample_fixed(filtered_data, max_len).values\n","          \n","        if masking:\n","            ts_values = filtered_data.values\n","            ts_values = np.vstack((ts_values, mask*np.ones((max_len - len(ts_values), ts_values.shape[1]))))\n","          \n","        all_ts_values.append(ts_values)\n","\n","    return np.array(all_ts_values)\n","  \n","def window_time_series(data, labels, processes, cols, window_size=25):\n","    windows = []\n","    y = []\n","    \n","    for col in ts_cols:\n","      data[col] = (data[col] - data[col].min()) / (data[col].max() - data[col].min())\n","    \n","    for ix, process in enumerate(processes):\n","        filtered_data = data[data['process_id'] == process]\n","        filtered_data = filtered_data.sort_values(by='timestamp')\n","        filtered_data = filtered_data.reset_index(drop=True)\n","        filtered_data = filtered_data[cols].astype(float)\n","        \n","        ts_values = filtered_data[ts_cols].values\n","        \n","        for i in range(len(ts_values), window_size, -window_size):\n","            windows.append(ts_values[i - window_size:i])\n","            y.append(labels.loc[process])\n","            \n","    return np.array(windows), np.array(y)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"KwBoIgv6qhQ9","colab_type":"code","outputId":"79c56dd7-8dc3-4e64-e9f4-ba6dc400cbd0","executionInfo":{"status":"ok","timestamp":1548363149737,"user_tz":-60,"elapsed":1043,"user":{"displayName":"Gilles Vandewiele","photoUrl":"","userId":"04070140729205161481"}},"colab":{"base_uri":"https://localhost:8080/","height":55}},"cell_type":"code","source":["PROCESS_COMBINATION = 3\n","\n","phases = {\n","    15: ['pre_rinse', 'caustic', 'intermediate_rinse', 'acid'],\n","    3:  ['pre_rinse', 'caustic'],\n","    7:  ['pre_rinse', 'caustic', 'intermediate_rinse'],\n","    1:  ['pre_rinse'],\n","    8:  ['acid'],\n","    2:  ['caustic'],\n","    6:  ['caustic', 'intermediate_rinse'],\n","    14: ['caustic', 'intermediate_rinse', 'acid'],\n","}\n","\n","ts_cols = [\n","    'supply_flow',\n","    'supply_pressure',\n","    'return_temperature',\n","    'return_conductivity',\n","    'return_turbidity',\n","    'return_flow',\n","    'tank_level_pre_rinse',\n","    'tank_level_caustic',\n","    'tank_level_acid',\n","    'tank_level_clean_water',\n","    'tank_temperature_pre_rinse',\n","    'tank_temperature_caustic',\n","    'tank_temperature_acid',\n","    'tank_concentration_caustic',\n","    'tank_concentration_acid',\n","    'supply_pump',\n","    'supply_pre_rinse',\n","    'supply_caustic',\n","    'return_caustic',\n","    'supply_acid',\n","    'return_acid',\n","    'supply_clean_water',\n","    'return_recovery_water',\n","    'return_drain',\n","    'object_low_level'\n","]\n","\n","\"\"\"\n","'tank_level_pre_rinse',\n","'tank_level_caustic',\n","'tank_level_acid',\n","'tank_level_clean_water',\n","'tank_temperature_pre_rinse',\n","'tank_temperature_caustic',\n","'tank_temperature_acid',\n","'tank_concentration_caustic',\n","'tank_concentration_acid',\n","'supply_pump',\n","'supply_pre_rinse',\n","'supply_caustic',\n","'return_caustic',\n","'supply_acid',\n","'return_acid',\n","'supply_clean_water',\n","'return_recovery_water',\n","'return_drain',\n","'object_low_level'\n","\"\"\""],"execution_count":25,"outputs":[{"output_type":"execute_result","data":{"text/plain":["\"\\n'tank_level_pre_rinse',\\n'tank_level_caustic',\\n'tank_level_acid',\\n'tank_level_clean_water',\\n'tank_temperature_pre_rinse',\\n'tank_temperature_caustic',\\n'tank_temperature_acid',\\n'tank_concentration_caustic',\\n'tank_concentration_acid',\\n'supply_pump',\\n'supply_pre_rinse',\\n'supply_caustic',\\n'return_caustic',\\n'supply_acid',\\n'return_acid',\\n'supply_clean_water',\\n'return_recovery_water',\\n'return_drain',\\n'object_low_level'\\n\""]},"metadata":{"tags":[]},"execution_count":25}]},{"metadata":{"id":"kOwqSmT9pfAc","colab_type":"code","outputId":"b51bf547-28cb-47e2-826a-2c2a7bd5b848","executionInfo":{"status":"ok","timestamp":1548363191629,"user_tz":-60,"elapsed":42391,"user":{"displayName":"Gilles Vandewiele","photoUrl":"","userId":"04070140729205161481"}},"colab":{"base_uri":"https://localhost:8080/","height":54}},"cell_type":"code","source":["train_df = pd.read_csv('/content/drive/My Drive/Rinse Over Run/train_values.csv', index_col=0, parse_dates=['timestamp'])\n","labels = pd.read_csv('/content/drive/My Drive/Rinse Over Run/train_labels.csv', index_col=0)\n","train_features = pd.read_csv('/content/drive/My Drive/Rinse Over Run/train_features_{}.csv'.format(PROCESS_COMBINATION), index_col='process_id')\n","\n","train_procs = set(pd.read_csv('/content/drive/My Drive/Rinse Over Run/train_features_adv_{}.csv'.format(PROCESS_COMBINATION), index_col='process_id').index)\n","val_procs = set(pd.read_csv('/content/drive/My Drive/Rinse Over Run/val_features_adv_{}.csv'.format(PROCESS_COMBINATION), index_col='process_id').index)\n","\n","#train_procs = np.random.choice(train_procs, replace=False, size=250)\n","#val_procs = np.random.choice(val_procs, replace=False, size=250)"],"execution_count":26,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/numpy/lib/arraysetops.py:472: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n","  mask |= (ar1 == a)\n"],"name":"stderr"}]},{"metadata":{"id":"cApXxcnnWPQU","colab_type":"code","colab":{}},"cell_type":"code","source":["#train_df.groupby('process_id')['timestamp'].count().max()"],"execution_count":0,"outputs":[]},{"metadata":{"id":"hh-0HBZ6po4F","colab_type":"code","outputId":"7c153fa6-20d7-48b2-adda-f2a7abb02ba5","executionInfo":{"status":"ok","timestamp":1548364480624,"user_tz":-60,"elapsed":43194,"user":{"displayName":"Gilles Vandewiele","photoUrl":"","userId":"04070140729205161481"}},"colab":{"base_uri":"https://localhost:8080/","height":35}},"cell_type":"code","source":["filtered_data = filter_data(train_df, train_procs, phases[PROCESS_COMBINATION], ts_cols)\n","#train_windows, train_labels = window_time_series(filtered_data, labels, train_procs, ts_cols)\n","#train_labels = np.log(train_labels)\n","time_series = get_time_series(filtered_data, train_procs, ts_cols, masking=True)\n","train_labels = np.log(labels.loc[train_procs].values)\n","#train_mean = np.mean(train_labels)\n","#train_std = np.std(train_labels)\n","#train_labels = (train_labels - train_mean) / train_std\n","\n","filtered_data = filter_data(train_df, val_procs, phases[PROCESS_COMBINATION], ts_cols)\n","#val_windows, val_labels = window_time_series(filtered_data, labels, val_procs, ts_cols)\n","#val_labels = np.log(val_labels)\n","val_time_series = get_time_series(filtered_data, val_procs, ts_cols, masking=True)\n","val_labels = np.log(labels.loc[val_procs].values)\n","#val_labels = (val_labels - train_mean) / train_std\n","\n","print(time_series.shape, val_time_series.shape)"],"execution_count":39,"outputs":[{"output_type":"stream","text":["(4269, 1000, 25) (474, 1000, 25)\n"],"name":"stdout"}]},{"metadata":{"id":"FJvbyN7D-YgN","colab_type":"code","outputId":"cc4a2b71-4195-4fc9-f0f8-5cc25d286bc9","executionInfo":{"status":"error","timestamp":1548358529965,"user_tz":-60,"elapsed":1056,"user":{"displayName":"Gilles Vandewiele","photoUrl":"","userId":"04070140729205161481"}},"colab":{"base_uri":"https://localhost:8080/","height":229}},"cell_type":"code","source":["def custom_mape_np(approxes, targets):\n","    return np.mean(np.abs(np.subtract(approxes, targets)) / np.maximum(np.abs(targets), 290000))\n","\n","print(model.predict(val_windows) * train_std + train_mean)\n","custom_mape_np(np.array(model.predict(val_windows) * train_std + train_mean), val_labels * train_std + train_mean)"],"execution_count":16,"outputs":[{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-16-655c3057655d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubtract\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mapproxes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmaximum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m290000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_windows\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mtrain_std\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtrain_mean\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mcustom_mape_np\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_windows\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mtrain_std\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtrain_mean\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_labels\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mtrain_std\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtrain_mean\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"]}]},{"metadata":{"id":"MlQZTKcKzsRS","colab_type":"code","colab":{}},"cell_type":"code","source":["import keras.backend as K\n","def custom_mape_exp(y_true,y_pred):\n","    y_true = K.exp(y_true)\n","    y_pred = K.exp(y_pred)\n","    \n","    diff = K.abs((y_true - y_pred) / K.clip(K.abs(y_true),\n","                                            290000,\n","                                            None))\n","    return 100. * K.mean(diff, axis=-1)\n","  \n","def custom_smape_exp(y_true,y_pred):\n","    y_true = K.exp(y_true)\n","    y_pred = K.exp(y_pred)\n","  \n","    return K.mean(K.abs(y_pred - y_true) / (y_pred + y_true))\n","  \n","def custom_mape(y_true,y_pred):\n","    return K.mean(K.abs(y_pred - y_true) / K.maximum(K.abs(y_true), np.log(290000)))"],"execution_count":0,"outputs":[]},{"metadata":{"id":"svRMmTLMwBNG","colab_type":"code","colab":{}},"cell_type":"code","source":["class NBatchLogger(keras.callbacks.Callback):\n","    def __init__(self, test_data, display=50):\n","        self.display = display\n","        self.test_data = test_data\n","        self.seen = 0\n","    def on_batch_end(self, epoch, logs={}):\n","        self.seen += 1\n","        if self.seen % self.display == 0:\n","            x, y = self.validation_data\n","            val_loss = self.model.evaluate(x, y, verbose=0)\n","            print('\\n[Epoch #{}] train loss {} - val loss {}\\n'.format(self.seen, logs.get('loss'), val_loss)) "],"execution_count":0,"outputs":[]},{"metadata":{"id":"vNcB9_sepuGP","colab_type":"code","outputId":"307938dd-45c0-457f-a07f-adef405c1c97","executionInfo":{"status":"error","timestamp":1548367114279,"user_tz":-60,"elapsed":1943488,"user":{"displayName":"Gilles Vandewiele","photoUrl":"","userId":"04070140729205161481"}},"colab":{"base_uri":"https://localhost:8080/","height":5392}},"cell_type":"code","source":["model = models.Sequential()\n","\n","model.add(layers.Conv1D(1024, 7, activation='relu', input_shape=(1000, len(ts_cols))))\n","model.add(layers.BatchNormalization())\n","#model.add(layers.Dropout(0.3))\n","model.add(layers.MaxPooling1D(8))\n","\n","model.add(layers.Conv1D(1024, 5, activation='relu'))\n","model.add(layers.BatchNormalization())\n","#model.add(layers.Dropout(0.3))\n","model.add(layers.MaxPooling1D(8))\n","\n","model.add(layers.Conv1D(1024, 3, activation='relu'))\n","model.add(layers.BatchNormalization())\n","#model.add(layers.Dropout(0.3))\n","model.add(layers.MaxPooling1D(8))\n","\n","model.add(layers.Flatten())\n","#model.add(layers.Dropout(0.5))\n","\n","model.add(layers.Dense(512, activation='relu'))\n","#model.add(layers.Dropout(0.5))\n","model.add(layers.Dense(1, activation='sigmoid'))\n","\n","model.compile(optimizer=optimizers.Adam(lr=0.001), loss='mean_absolute_percentage_error')\n","\n","print(model.summary())\n","\n","model.fit(time_series, train_labels, batch_size=128, verbose=2,\n","          epochs=1000, validation_data=(val_time_series, val_labels),\n","          callbacks=[callbacks.EarlyStopping(patience=100)])"],"execution_count":44,"outputs":[{"output_type":"stream","text":["_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","conv1d_40 (Conv1D)           (None, 994, 1024)         180224    \n","_________________________________________________________________\n","batch_normalization_40 (Batc (None, 994, 1024)         4096      \n","_________________________________________________________________\n","max_pooling1d_40 (MaxPooling (None, 124, 1024)         0         \n","_________________________________________________________________\n","conv1d_41 (Conv1D)           (None, 120, 1024)         5243904   \n","_________________________________________________________________\n","batch_normalization_41 (Batc (None, 120, 1024)         4096      \n","_________________________________________________________________\n","max_pooling1d_41 (MaxPooling (None, 15, 1024)          0         \n","_________________________________________________________________\n","conv1d_42 (Conv1D)           (None, 13, 1024)          3146752   \n","_________________________________________________________________\n","batch_normalization_42 (Batc (None, 13, 1024)          4096      \n","_________________________________________________________________\n","max_pooling1d_42 (MaxPooling (None, 1, 1024)           0         \n","_________________________________________________________________\n","flatten_14 (Flatten)         (None, 1024)              0         \n","_________________________________________________________________\n","dense_27 (Dense)             (None, 512)               524800    \n","_________________________________________________________________\n","dense_28 (Dense)             (None, 1)                 513       \n","=================================================================\n","Total params: 9,108,481\n","Trainable params: 9,102,337\n","Non-trainable params: 6,144\n","_________________________________________________________________\n","None\n","Train on 4269 samples, validate on 474 samples\n","Epoch 1/1000\n"," - 27s - loss: 96.2241 - val_loss: 96.2210\n","Epoch 2/1000\n"," - 18s - loss: 96.1600 - val_loss: 96.1574\n","Epoch 3/1000\n"," - 18s - loss: 96.0959 - val_loss: 96.0940\n","Epoch 4/1000\n"," - 18s - loss: 96.0322 - val_loss: 96.0309\n","Epoch 5/1000\n"," - 18s - loss: 95.9687 - val_loss: 95.9681\n","Epoch 6/1000\n"," - 18s - loss: 95.9056 - val_loss: 95.9056\n","Epoch 7/1000\n"," - 18s - loss: 95.8428 - val_loss: 95.8436\n","Epoch 8/1000\n"," - 18s - loss: 95.7804 - val_loss: 95.7819\n","Epoch 9/1000\n"," - 18s - loss: 95.7184 - val_loss: 95.7206\n","Epoch 10/1000\n"," - 18s - loss: 95.6569 - val_loss: 95.6600\n","Epoch 11/1000\n"," - 18s - loss: 95.5960 - val_loss: 95.5997\n","Epoch 12/1000\n"," - 18s - loss: 95.5356 - val_loss: 95.5401\n","Epoch 13/1000\n"," - 18s - loss: 95.4758 - val_loss: 95.4812\n","Epoch 14/1000\n"," - 18s - loss: 95.4168 - val_loss: 95.4229\n","Epoch 15/1000\n"," - 18s - loss: 95.3583 - val_loss: 95.3654\n","Epoch 16/1000\n"," - 18s - loss: 95.3007 - val_loss: 95.3086\n","Epoch 17/1000\n"," - 18s - loss: 95.2437 - val_loss: 95.2525\n","Epoch 18/1000\n"," - 18s - loss: 95.1876 - val_loss: 95.1972\n","Epoch 19/1000\n"," - 18s - loss: 95.1323 - val_loss: 95.1427\n","Epoch 20/1000\n"," - 18s - loss: 95.0778 - val_loss: 95.0892\n","Epoch 21/1000\n"," - 18s - loss: 95.0242 - val_loss: 95.0364\n","Epoch 22/1000\n"," - 18s - loss: 94.9714 - val_loss: 94.9845\n","Epoch 23/1000\n"," - 18s - loss: 94.9195 - val_loss: 94.9336\n","Epoch 24/1000\n"," - 18s - loss: 94.8685 - val_loss: 94.8834\n","Epoch 25/1000\n"," - 18s - loss: 94.8185 - val_loss: 94.8342\n","Epoch 26/1000\n"," - 18s - loss: 94.7693 - val_loss: 94.7859\n","Epoch 27/1000\n"," - 18s - loss: 94.7211 - val_loss: 94.7386\n","Epoch 28/1000\n"," - 18s - loss: 94.6738 - val_loss: 94.6921\n","Epoch 29/1000\n"," - 18s - loss: 94.6274 - val_loss: 94.6466\n","Epoch 30/1000\n"," - 18s - loss: 94.5820 - val_loss: 94.6020\n","Epoch 31/1000\n"," - 18s - loss: 94.5374 - val_loss: 94.5583\n","Epoch 32/1000\n"," - 18s - loss: 94.4938 - val_loss: 94.5156\n","Epoch 33/1000\n"," - 18s - loss: 94.4512 - val_loss: 94.4737\n","Epoch 34/1000\n"," - 18s - loss: 94.4094 - val_loss: 94.4327\n","Epoch 35/1000\n"," - 18s - loss: 94.3685 - val_loss: 94.3927\n","Epoch 36/1000\n"," - 18s - loss: 94.3285 - val_loss: 94.3535\n","Epoch 37/1000\n"," - 18s - loss: 94.2894 - val_loss: 94.3151\n","Epoch 38/1000\n"," - 18s - loss: 94.2512 - val_loss: 94.2777\n","Epoch 39/1000\n"," - 18s - loss: 94.2138 - val_loss: 94.2410\n","Epoch 40/1000\n"," - 18s - loss: 94.1773 - val_loss: 94.2052\n","Epoch 41/1000\n"," - 18s - loss: 94.1416 - val_loss: 94.1702\n","Epoch 42/1000\n"," - 18s - loss: 94.1067 - val_loss: 94.1361\n","Epoch 43/1000\n"," - 18s - loss: 94.0726 - val_loss: 94.1026\n","Epoch 44/1000\n"," - 18s - loss: 94.0394 - val_loss: 94.0700\n","Epoch 45/1000\n"," - 18s - loss: 94.0068 - val_loss: 94.0382\n","Epoch 46/1000\n"," - 18s - loss: 93.9751 - val_loss: 94.0071\n","Epoch 47/1000\n"," - 18s - loss: 93.9441 - val_loss: 93.9767\n","Epoch 48/1000\n"," - 18s - loss: 93.9138 - val_loss: 93.9470\n","Epoch 49/1000\n"," - 18s - loss: 93.8843 - val_loss: 93.9181\n","Epoch 50/1000\n"," - 18s - loss: 93.8554 - val_loss: 93.8898\n","Epoch 51/1000\n"," - 18s - loss: 93.8272 - val_loss: 93.8622\n","Epoch 52/1000\n"," - 18s - loss: 93.7997 - val_loss: 93.8353\n","Epoch 53/1000\n"," - 18s - loss: 93.7729 - val_loss: 93.8090\n","Epoch 54/1000\n"," - 18s - loss: 93.7466 - val_loss: 93.7833\n","Epoch 55/1000\n"," - 18s - loss: 93.7211 - val_loss: 93.7582\n","Epoch 56/1000\n"," - 18s - loss: 93.6961 - val_loss: 93.7338\n","Epoch 57/1000\n"," - 18s - loss: 93.6717 - val_loss: 93.7099\n","Epoch 58/1000\n"," - 18s - loss: 93.6479 - val_loss: 93.6865\n","Epoch 59/1000\n"," - 18s - loss: 93.6246 - val_loss: 93.6638\n","Epoch 60/1000\n"," - 18s - loss: 93.6019 - val_loss: 93.6416\n","Epoch 61/1000\n"," - 18s - loss: 93.5798 - val_loss: 93.6198\n","Epoch 62/1000\n"," - 18s - loss: 93.5582 - val_loss: 93.5987\n","Epoch 63/1000\n"," - 18s - loss: 93.5370 - val_loss: 93.5780\n","Epoch 64/1000\n"," - 18s - loss: 93.5164 - val_loss: 93.5578\n","Epoch 65/1000\n"," - 18s - loss: 93.4963 - val_loss: 93.5381\n","Epoch 66/1000\n"," - 18s - loss: 93.4766 - val_loss: 93.5188\n","Epoch 67/1000\n"," - 18s - loss: 93.4574 - val_loss: 93.5000\n","Epoch 68/1000\n"," - 18s - loss: 93.4387 - val_loss: 93.4816\n","Epoch 69/1000\n"," - 18s - loss: 93.4203 - val_loss: 93.4636\n","Epoch 70/1000\n"," - 18s - loss: 93.4024 - val_loss: 93.4461\n","Epoch 71/1000\n"," - 18s - loss: 93.3850 - val_loss: 93.4290\n","Epoch 72/1000\n"," - 18s - loss: 93.3679 - val_loss: 93.4122\n","Epoch 73/1000\n"," - 18s - loss: 93.3512 - val_loss: 93.3959\n","Epoch 74/1000\n"," - 18s - loss: 93.3349 - val_loss: 93.3799\n","Epoch 75/1000\n"," - 18s - loss: 93.3190 - val_loss: 93.3643\n","Epoch 76/1000\n"," - 18s - loss: 93.3034 - val_loss: 93.3490\n","Epoch 77/1000\n"," - 18s - loss: 93.2882 - val_loss: 93.3341\n","Epoch 78/1000\n"," - 18s - loss: 93.2733 - val_loss: 93.3196\n","Epoch 79/1000\n"," - 18s - loss: 93.2588 - val_loss: 93.3053\n","Epoch 80/1000\n"," - 18s - loss: 93.2446 - val_loss: 93.2914\n","Epoch 81/1000\n"," - 18s - loss: 93.2307 - val_loss: 93.2778\n","Epoch 82/1000\n"," - 18s - loss: 93.2171 - val_loss: 93.2645\n","Epoch 83/1000\n"," - 18s - loss: 93.2039 - val_loss: 93.2515\n","Epoch 84/1000\n"," - 18s - loss: 93.1909 - val_loss: 93.2387\n","Epoch 85/1000\n"," - 18s - loss: 93.1782 - val_loss: 93.2263\n","Epoch 86/1000\n"," - 18s - loss: 93.1658 - val_loss: 93.2141\n","Epoch 87/1000\n"," - 18s - loss: 93.1536 - val_loss: 93.2022\n","Epoch 88/1000\n"," - 18s - loss: 93.1418 - val_loss: 93.1906\n","Epoch 89/1000\n"," - 18s - loss: 93.1301 - val_loss: 93.1792\n","Epoch 90/1000\n"," - 18s - loss: 93.1188 - val_loss: 93.1680\n","Epoch 91/1000\n"," - 18s - loss: 93.1076 - val_loss: 93.1571\n","Epoch 92/1000\n"," - 18s - loss: 93.0968 - val_loss: 93.1464\n","Epoch 93/1000\n"," - 18s - loss: 93.0861 - val_loss: 93.1360\n","Epoch 94/1000\n"," - 18s - loss: 93.0757 - val_loss: 93.1258\n","Epoch 95/1000\n"," - 18s - loss: 93.0655 - val_loss: 93.1158\n","Epoch 96/1000\n"," - 18s - loss: 93.0555 - val_loss: 93.1060\n","Epoch 97/1000\n"," - 18s - loss: 93.0457 - val_loss: 93.0964\n","Epoch 98/1000\n"," - 18s - loss: 93.0361 - val_loss: 93.0870\n","Epoch 99/1000\n"," - 18s - loss: 93.0268 - val_loss: 93.0778\n","Epoch 100/1000\n"," - 18s - loss: 93.0176 - val_loss: 93.0688\n","Epoch 101/1000\n"," - 18s - loss: 93.0086 - val_loss: 93.0599\n","Epoch 102/1000\n"," - 18s - loss: 92.9998 - val_loss: 93.0513\n","Epoch 103/1000\n"," - 18s - loss: 92.9911 - val_loss: 93.0428\n","Epoch 104/1000\n"," - 18s - loss: 92.9827 - val_loss: 93.0345\n","Epoch 105/1000\n"," - 18s - loss: 92.9744 - val_loss: 93.0264\n","Epoch 106/1000\n"," - 18s - loss: 92.9663 - val_loss: 93.0184\n","Epoch 107/1000\n"],"name":"stdout"},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-44-137483b1576a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     29\u001b[0m model.fit(time_series, train_labels, batch_size=128, verbose=2,\n\u001b[1;32m     30\u001b[0m           \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_time_series\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m           callbacks=[callbacks.EarlyStopping(patience=100)])\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1040\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2675\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2676\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1439\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1440\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"metadata":{"id":"STa55_x7lbWv","colab_type":"code","colab":{}},"cell_type":"code","source":["def custom_mape_np(approxes, targets):\n","    return np.mean(np.abs(np.subtract(approxes, targets)) / np.maximum(np.abs(targets), 290000))\n","\n","custom_mape_np(np.exp(model.predict(val_time_series)), np.exp(val_labels))"],"execution_count":0,"outputs":[]},{"metadata":{"id":"FqM8LJQgOCwR","colab_type":"code","outputId":"9349ee55-e618-49fc-dbcd-e9611b4d7531","executionInfo":{"status":"ok","timestamp":1548268442159,"user_tz":-60,"elapsed":446832,"user":{"displayName":"Gilles Vandewiele","photoUrl":"","userId":"04070140729205161481"}},"colab":{"base_uri":"https://localhost:8080/","height":37081}},"cell_type":"code","source":["model = models.Sequential()\n","\n","model.add(layers.Masking(0, name=\"input\", input_shape=(25, len(ts_cols))))\n","model.add(layers.GRU(128, return_sequences=False, name='lstm1')) #layers.Bidirectional()\n","model.add(layers.Dense(64))\n","model.add(layers.Dense(1, name='output'))\n","\n","print(model.summary())\n","\n","model.compile(optimizers.Adam(), loss='mean_absolute_percentage_error')\n","\n","#model.add(layers.TimeDistributed(layers.Dense(1)))\n","#model.add(layers.Dropout(0.1, name='drop1'))\n","#model.add(layers.Dense(64, activation='relu', name='dense1'))\n","#model.add(layers.Dropout(0.1, name='drop1'))\n","#model.add(layers.Dense(64, activation='relu', name='dense2'))\n","#model.add(layers.Dense(64, activation='relu', name='dense3'))\n","#model.add(layers.Dropout(0.15, name='drop3'))\n","\n","model.fit(train_windows, train_labels, batch_size=256, \n","          epochs=1000, validation_data=(val_windows, val_labels))\n","          #callbacks=[callbacks.EarlyStopping(patience=25)])"],"execution_count":0,"outputs":[{"output_type":"stream","text":["_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","input (Masking)              (None, 25, 2)             0         \n","_________________________________________________________________\n","lstm1 (GRU)                  (None, 128)               50304     \n","_________________________________________________________________\n","dense_52 (Dense)             (None, 64)                8256      \n","_________________________________________________________________\n","output (Dense)               (None, 1)                 65        \n","=================================================================\n","Total params: 58,625\n","Trainable params: 58,625\n","Non-trainable params: 0\n","_________________________________________________________________\n","None\n","Train on 889 samples, validate on 1390 samples\n","Epoch 1/1000\n","889/889 [==============================] - 10s 11ms/step - loss: 107.1989 - val_loss: 100.7409\n","Epoch 2/1000\n","889/889 [==============================] - 0s 487us/step - loss: 104.7768 - val_loss: 100.2255\n","Epoch 3/1000\n","889/889 [==============================] - 0s 481us/step - loss: 108.0984 - val_loss: 100.5180\n","Epoch 4/1000\n","889/889 [==============================] - 0s 496us/step - loss: 109.9765 - val_loss: 99.9433\n","Epoch 5/1000\n","889/889 [==============================] - 0s 490us/step - loss: 114.7244 - val_loss: 97.4141\n","Epoch 6/1000\n","889/889 [==============================] - 0s 488us/step - loss: 110.2237 - val_loss: 97.3327\n","Epoch 7/1000\n","889/889 [==============================] - 0s 487us/step - loss: 108.7427 - val_loss: 96.0935\n","Epoch 8/1000\n","889/889 [==============================] - 0s 485us/step - loss: 103.2028 - val_loss: 96.7364\n","Epoch 9/1000\n","889/889 [==============================] - 0s 484us/step - loss: 100.7968 - val_loss: 98.2746\n","Epoch 10/1000\n","889/889 [==============================] - 0s 482us/step - loss: 103.4071 - val_loss: 98.5517\n","Epoch 11/1000\n","889/889 [==============================] - 0s 500us/step - loss: 101.0664 - val_loss: 97.6847\n","Epoch 12/1000\n","889/889 [==============================] - 0s 479us/step - loss: 100.8449 - val_loss: 97.0777\n","Epoch 13/1000\n","889/889 [==============================] - 0s 479us/step - loss: 103.6194 - val_loss: 96.0564\n","Epoch 14/1000\n","889/889 [==============================] - 0s 486us/step - loss: 101.7626 - val_loss: 95.7760\n","Epoch 15/1000\n","889/889 [==============================] - 0s 483us/step - loss: 102.0165 - val_loss: 96.3605\n","Epoch 16/1000\n","889/889 [==============================] - 0s 485us/step - loss: 105.8051 - val_loss: 97.4451\n","Epoch 17/1000\n","889/889 [==============================] - 0s 485us/step - loss: 102.7756 - val_loss: 96.9316\n","Epoch 18/1000\n","889/889 [==============================] - 0s 500us/step - loss: 106.6925 - val_loss: 95.8548\n","Epoch 19/1000\n","889/889 [==============================] - 0s 472us/step - loss: 103.3844 - val_loss: 95.7585\n","Epoch 20/1000\n","889/889 [==============================] - 0s 482us/step - loss: 105.3438 - val_loss: 95.4793\n","Epoch 21/1000\n","889/889 [==============================] - 0s 490us/step - loss: 101.0438 - val_loss: 95.7564\n","Epoch 22/1000\n","889/889 [==============================] - 0s 477us/step - loss: 100.4531 - val_loss: 96.1365\n","Epoch 23/1000\n","889/889 [==============================] - 0s 488us/step - loss: 100.1721 - val_loss: 95.9587\n","Epoch 24/1000\n","889/889 [==============================] - 0s 479us/step - loss: 100.2287 - val_loss: 95.2213\n","Epoch 25/1000\n","889/889 [==============================] - 0s 497us/step - loss: 104.9754 - val_loss: 94.7338\n","Epoch 26/1000\n","889/889 [==============================] - 0s 483us/step - loss: 103.0952 - val_loss: 95.3967\n","Epoch 27/1000\n","889/889 [==============================] - 0s 480us/step - loss: 104.7086 - val_loss: 95.1847\n","Epoch 28/1000\n","889/889 [==============================] - 0s 488us/step - loss: 101.0605 - val_loss: 95.1713\n","Epoch 29/1000\n","889/889 [==============================] - 0s 478us/step - loss: 100.3975 - val_loss: 95.7922\n","Epoch 30/1000\n","889/889 [==============================] - 0s 487us/step - loss: 101.3793 - val_loss: 95.8954\n","Epoch 31/1000\n","889/889 [==============================] - 0s 471us/step - loss: 101.6115 - val_loss: 95.7596\n","Epoch 32/1000\n","889/889 [==============================] - 0s 483us/step - loss: 102.2323 - val_loss: 95.2683\n","Epoch 33/1000\n","889/889 [==============================] - 0s 489us/step - loss: 100.9758 - val_loss: 95.1608\n","Epoch 34/1000\n","889/889 [==============================] - 0s 482us/step - loss: 101.0802 - val_loss: 95.1143\n","Epoch 35/1000\n","889/889 [==============================] - 0s 491us/step - loss: 100.4364 - val_loss: 95.3477\n","Epoch 36/1000\n","889/889 [==============================] - 0s 486us/step - loss: 102.6652 - val_loss: 95.6452\n","Epoch 37/1000\n","889/889 [==============================] - 0s 498us/step - loss: 101.5065 - val_loss: 95.4084\n","Epoch 38/1000\n","889/889 [==============================] - 0s 477us/step - loss: 99.6561 - val_loss: 96.0078\n","Epoch 39/1000\n","889/889 [==============================] - 0s 478us/step - loss: 99.9418 - val_loss: 96.1125\n","Epoch 40/1000\n","889/889 [==============================] - 0s 495us/step - loss: 99.6765 - val_loss: 95.2869\n","Epoch 41/1000\n","889/889 [==============================] - 0s 490us/step - loss: 101.4558 - val_loss: 95.1356\n","Epoch 42/1000\n","889/889 [==============================] - 0s 495us/step - loss: 101.2858 - val_loss: 95.1805\n","Epoch 43/1000\n","889/889 [==============================] - 0s 481us/step - loss: 101.1196 - val_loss: 95.4770\n","Epoch 44/1000\n","889/889 [==============================] - 0s 483us/step - loss: 99.2706 - val_loss: 96.1380\n","Epoch 45/1000\n","889/889 [==============================] - 0s 464us/step - loss: 100.8862 - val_loss: 95.6857\n","Epoch 46/1000\n","889/889 [==============================] - 0s 471us/step - loss: 99.9857 - val_loss: 94.9565\n","Epoch 47/1000\n","889/889 [==============================] - 0s 468us/step - loss: 99.4534 - val_loss: 94.5277\n","Epoch 48/1000\n","889/889 [==============================] - 0s 460us/step - loss: 99.7830 - val_loss: 94.4952\n","Epoch 49/1000\n","889/889 [==============================] - 0s 466us/step - loss: 99.5184 - val_loss: 94.6875\n","Epoch 50/1000\n","889/889 [==============================] - 0s 454us/step - loss: 99.4473 - val_loss: 94.5172\n","Epoch 51/1000\n","889/889 [==============================] - 0s 457us/step - loss: 101.5408 - val_loss: 94.4387\n","Epoch 52/1000\n","889/889 [==============================] - 0s 465us/step - loss: 100.2496 - val_loss: 94.1993\n","Epoch 53/1000\n","889/889 [==============================] - 0s 465us/step - loss: 102.9748 - val_loss: 95.2257\n","Epoch 54/1000\n","889/889 [==============================] - 0s 470us/step - loss: 101.5017 - val_loss: 95.8825\n","Epoch 55/1000\n","889/889 [==============================] - 0s 460us/step - loss: 100.9716 - val_loss: 95.3653\n","Epoch 56/1000\n","889/889 [==============================] - 0s 461us/step - loss: 100.9210 - val_loss: 94.9178\n","Epoch 57/1000\n","889/889 [==============================] - 0s 466us/step - loss: 100.2074 - val_loss: 94.7712\n","Epoch 58/1000\n","889/889 [==============================] - 0s 466us/step - loss: 99.8523 - val_loss: 94.7821\n","Epoch 59/1000\n","889/889 [==============================] - 0s 477us/step - loss: 99.5846 - val_loss: 95.1481\n","Epoch 60/1000\n","889/889 [==============================] - 0s 468us/step - loss: 100.1956 - val_loss: 96.2142\n","Epoch 61/1000\n","889/889 [==============================] - 0s 469us/step - loss: 103.2621 - val_loss: 96.3230\n","Epoch 62/1000\n","889/889 [==============================] - 0s 460us/step - loss: 101.4281 - val_loss: 97.6250\n","Epoch 63/1000\n","889/889 [==============================] - 0s 457us/step - loss: 106.3522 - val_loss: 97.7305\n","Epoch 64/1000\n","889/889 [==============================] - 0s 477us/step - loss: 103.4639 - val_loss: 96.6863\n","Epoch 65/1000\n","889/889 [==============================] - 0s 481us/step - loss: 100.6162 - val_loss: 95.6570\n","Epoch 66/1000\n","889/889 [==============================] - 0s 470us/step - loss: 100.3961 - val_loss: 95.3605\n","Epoch 67/1000\n","889/889 [==============================] - 0s 487us/step - loss: 100.8558 - val_loss: 95.6322\n","Epoch 68/1000\n","889/889 [==============================] - 0s 471us/step - loss: 103.0824 - val_loss: 97.2361\n","Epoch 69/1000\n","889/889 [==============================] - 0s 487us/step - loss: 100.8108 - val_loss: 98.2603\n","Epoch 70/1000\n","889/889 [==============================] - 0s 467us/step - loss: 102.7427 - val_loss: 98.2999\n","Epoch 71/1000\n","889/889 [==============================] - 0s 494us/step - loss: 99.6072 - val_loss: 98.4926\n","Epoch 72/1000\n","889/889 [==============================] - 0s 480us/step - loss: 103.9574 - val_loss: 98.3286\n","Epoch 73/1000\n","889/889 [==============================] - 0s 466us/step - loss: 101.5993 - val_loss: 98.1705\n","Epoch 74/1000\n","889/889 [==============================] - 0s 480us/step - loss: 102.3096 - val_loss: 98.2418\n","Epoch 75/1000\n","889/889 [==============================] - 0s 475us/step - loss: 102.7457 - val_loss: 99.1563\n","Epoch 76/1000\n","889/889 [==============================] - 0s 481us/step - loss: 100.8322 - val_loss: 100.5880\n","Epoch 77/1000\n","889/889 [==============================] - 0s 484us/step - loss: 101.4198 - val_loss: 100.7684\n","Epoch 78/1000\n","889/889 [==============================] - 0s 485us/step - loss: 102.7557 - val_loss: 99.2364\n","Epoch 79/1000\n","889/889 [==============================] - 0s 486us/step - loss: 102.3186 - val_loss: 95.6659\n","Epoch 80/1000\n","889/889 [==============================] - 0s 481us/step - loss: 102.0297 - val_loss: 93.9228\n","Epoch 81/1000\n","889/889 [==============================] - 0s 493us/step - loss: 101.5845 - val_loss: 93.6747\n","Epoch 82/1000\n","889/889 [==============================] - 0s 473us/step - loss: 101.4189 - val_loss: 93.7328\n","Epoch 83/1000\n","889/889 [==============================] - 0s 483us/step - loss: 100.8405 - val_loss: 93.8245\n","Epoch 84/1000\n","889/889 [==============================] - 0s 475us/step - loss: 102.5653 - val_loss: 94.9171\n","Epoch 85/1000\n","889/889 [==============================] - 0s 472us/step - loss: 99.8384 - val_loss: 95.6087\n","Epoch 86/1000\n","889/889 [==============================] - 0s 486us/step - loss: 99.8488 - val_loss: 95.6876\n","Epoch 87/1000\n","889/889 [==============================] - 0s 471us/step - loss: 99.1399 - val_loss: 95.1541\n","Epoch 88/1000\n","889/889 [==============================] - 0s 482us/step - loss: 99.8735 - val_loss: 95.5321\n","Epoch 89/1000\n","889/889 [==============================] - 0s 480us/step - loss: 102.5445 - val_loss: 95.8995\n","Epoch 90/1000\n","889/889 [==============================] - 0s 502us/step - loss: 101.3558 - val_loss: 94.5172\n","Epoch 91/1000\n","889/889 [==============================] - 0s 467us/step - loss: 104.0990 - val_loss: 94.2554\n","Epoch 92/1000\n","889/889 [==============================] - 0s 463us/step - loss: 101.3271 - val_loss: 96.0261\n","Epoch 93/1000\n","889/889 [==============================] - 0s 480us/step - loss: 104.5997 - val_loss: 96.9056\n","Epoch 94/1000\n","889/889 [==============================] - 0s 476us/step - loss: 103.0589 - val_loss: 97.1840\n","Epoch 95/1000\n","889/889 [==============================] - 0s 506us/step - loss: 102.7125 - val_loss: 97.3107\n","Epoch 96/1000\n","889/889 [==============================] - 0s 472us/step - loss: 100.2469 - val_loss: 95.8013\n","Epoch 97/1000\n","889/889 [==============================] - 0s 469us/step - loss: 101.1289 - val_loss: 91.9777\n","Epoch 98/1000\n","889/889 [==============================] - 0s 481us/step - loss: 98.6663 - val_loss: 89.6237\n","Epoch 99/1000\n","889/889 [==============================] - 0s 469us/step - loss: 98.0967 - val_loss: 88.5754\n","Epoch 100/1000\n","889/889 [==============================] - 0s 477us/step - loss: 97.1050 - val_loss: 90.9773\n","Epoch 101/1000\n","889/889 [==============================] - 0s 462us/step - loss: 97.3709 - val_loss: 101.3057\n","Epoch 102/1000\n","889/889 [==============================] - 0s 469us/step - loss: 96.6995 - val_loss: 93.8673\n","Epoch 103/1000\n","889/889 [==============================] - 0s 488us/step - loss: 95.6127 - val_loss: 103.3509\n","Epoch 104/1000\n","889/889 [==============================] - 0s 472us/step - loss: 95.0727 - val_loss: 90.7617\n","Epoch 105/1000\n","889/889 [==============================] - 0s 475us/step - loss: 98.3834 - val_loss: 91.9305\n","Epoch 106/1000\n","889/889 [==============================] - 0s 476us/step - loss: 95.5891 - val_loss: 98.1819\n","Epoch 107/1000\n","889/889 [==============================] - 0s 485us/step - loss: 99.5307 - val_loss: 95.0788\n","Epoch 108/1000\n","889/889 [==============================] - 0s 461us/step - loss: 95.5748 - val_loss: 103.0522\n","Epoch 109/1000\n","889/889 [==============================] - 0s 461us/step - loss: 98.4601 - val_loss: 92.8820\n","Epoch 110/1000\n","889/889 [==============================] - 0s 470us/step - loss: 95.4147 - val_loss: 91.4919\n","Epoch 111/1000\n","889/889 [==============================] - 0s 479us/step - loss: 94.5978 - val_loss: 90.8728\n","Epoch 112/1000\n","889/889 [==============================] - 0s 496us/step - loss: 95.4532 - val_loss: 93.4617\n","Epoch 113/1000\n","889/889 [==============================] - 0s 470us/step - loss: 93.2228 - val_loss: 90.7723\n","Epoch 114/1000\n","889/889 [==============================] - 0s 472us/step - loss: 97.3050 - val_loss: 95.0915\n","Epoch 115/1000\n","889/889 [==============================] - 0s 482us/step - loss: 97.5022 - val_loss: 96.8336\n","Epoch 116/1000\n","889/889 [==============================] - 0s 477us/step - loss: 95.7871 - val_loss: 96.0836\n","Epoch 117/1000\n","889/889 [==============================] - 0s 476us/step - loss: 94.6968 - val_loss: 91.9619\n","Epoch 118/1000\n","889/889 [==============================] - 0s 469us/step - loss: 93.6270 - val_loss: 94.9906\n","Epoch 119/1000\n","889/889 [==============================] - 0s 491us/step - loss: 94.8672 - val_loss: 91.0901\n","Epoch 120/1000\n","889/889 [==============================] - 0s 470us/step - loss: 94.7062 - val_loss: 96.6201\n","Epoch 121/1000\n","889/889 [==============================] - 0s 476us/step - loss: 94.6897 - val_loss: 91.5100\n","Epoch 122/1000\n","889/889 [==============================] - 0s 479us/step - loss: 95.4733 - val_loss: 93.4593\n","Epoch 123/1000\n","889/889 [==============================] - 0s 480us/step - loss: 93.9707 - val_loss: 99.5950\n","Epoch 124/1000\n","889/889 [==============================] - 0s 484us/step - loss: 94.0180 - val_loss: 92.7741\n","Epoch 125/1000\n","889/889 [==============================] - 0s 487us/step - loss: 93.4242 - val_loss: 91.3728\n","Epoch 126/1000\n","889/889 [==============================] - 0s 471us/step - loss: 94.3801 - val_loss: 95.1142\n","Epoch 127/1000\n","889/889 [==============================] - 0s 485us/step - loss: 94.7152 - val_loss: 91.1160\n","Epoch 128/1000\n","889/889 [==============================] - 0s 485us/step - loss: 94.2547 - val_loss: 92.8586\n","Epoch 129/1000\n","889/889 [==============================] - 0s 494us/step - loss: 93.8360 - val_loss: 94.3975\n","Epoch 130/1000\n","889/889 [==============================] - 0s 487us/step - loss: 93.1292 - val_loss: 93.9829\n","Epoch 131/1000\n","889/889 [==============================] - 0s 491us/step - loss: 93.7188 - val_loss: 92.9120\n","Epoch 132/1000\n","889/889 [==============================] - 0s 482us/step - loss: 94.4299 - val_loss: 93.1207\n","Epoch 133/1000\n","889/889 [==============================] - 0s 473us/step - loss: 94.0689 - val_loss: 92.7696\n","Epoch 134/1000\n","889/889 [==============================] - 0s 494us/step - loss: 95.2065 - val_loss: 91.7091\n","Epoch 135/1000\n","889/889 [==============================] - 0s 476us/step - loss: 94.9288 - val_loss: 91.6610\n","Epoch 136/1000\n","889/889 [==============================] - 0s 488us/step - loss: 94.7245 - val_loss: 99.8170\n","Epoch 137/1000\n","889/889 [==============================] - 0s 472us/step - loss: 96.3047 - val_loss: 93.2663\n","Epoch 138/1000\n","889/889 [==============================] - 0s 475us/step - loss: 93.8889 - val_loss: 93.5995\n","Epoch 139/1000\n","889/889 [==============================] - 0s 477us/step - loss: 93.4716 - val_loss: 92.7798\n","Epoch 140/1000\n","889/889 [==============================] - 0s 470us/step - loss: 93.6711 - val_loss: 96.0037\n","Epoch 141/1000\n","889/889 [==============================] - 0s 479us/step - loss: 92.7564 - val_loss: 94.2135\n","Epoch 142/1000\n","889/889 [==============================] - 0s 467us/step - loss: 93.2663 - val_loss: 92.6870\n","Epoch 143/1000\n","889/889 [==============================] - 0s 490us/step - loss: 93.8491 - val_loss: 92.5133\n","Epoch 144/1000\n","889/889 [==============================] - 0s 479us/step - loss: 93.1755 - val_loss: 95.3894\n","Epoch 145/1000\n","889/889 [==============================] - 0s 470us/step - loss: 93.7401 - val_loss: 94.1605\n","Epoch 146/1000\n","889/889 [==============================] - 0s 482us/step - loss: 97.5216 - val_loss: 92.1491\n","Epoch 147/1000\n","889/889 [==============================] - 0s 480us/step - loss: 96.4768 - val_loss: 98.9636\n","Epoch 148/1000\n","889/889 [==============================] - 0s 483us/step - loss: 95.5088 - val_loss: 92.4465\n","Epoch 149/1000\n","889/889 [==============================] - 0s 474us/step - loss: 95.2215 - val_loss: 92.3132\n","Epoch 150/1000\n","889/889 [==============================] - 0s 466us/step - loss: 95.7037 - val_loss: 93.0908\n","Epoch 151/1000\n","889/889 [==============================] - 0s 477us/step - loss: 95.1188 - val_loss: 92.0050\n","Epoch 152/1000\n","889/889 [==============================] - 0s 470us/step - loss: 94.4222 - val_loss: 94.8296\n","Epoch 153/1000\n","889/889 [==============================] - 0s 480us/step - loss: 94.8125 - val_loss: 93.8658\n","Epoch 154/1000\n","889/889 [==============================] - 0s 469us/step - loss: 93.7172 - val_loss: 95.2080\n","Epoch 155/1000\n","889/889 [==============================] - 0s 489us/step - loss: 93.8300 - val_loss: 94.1847\n","Epoch 156/1000\n","889/889 [==============================] - 0s 481us/step - loss: 92.7576 - val_loss: 93.0034\n","Epoch 157/1000\n","889/889 [==============================] - 0s 474us/step - loss: 92.7578 - val_loss: 93.1303\n","Epoch 158/1000\n","889/889 [==============================] - 0s 472us/step - loss: 93.0117 - val_loss: 94.2509\n","Epoch 159/1000\n","889/889 [==============================] - 0s 463us/step - loss: 93.2810 - val_loss: 93.2906\n","Epoch 160/1000\n","889/889 [==============================] - 0s 482us/step - loss: 93.0868 - val_loss: 94.3549\n","Epoch 161/1000\n","889/889 [==============================] - 0s 467us/step - loss: 93.4643 - val_loss: 93.8002\n","Epoch 162/1000\n","889/889 [==============================] - 0s 470us/step - loss: 94.8683 - val_loss: 92.3536\n","Epoch 163/1000\n","889/889 [==============================] - 0s 475us/step - loss: 93.6275 - val_loss: 97.7201\n","Epoch 164/1000\n","889/889 [==============================] - 0s 463us/step - loss: 94.2638 - val_loss: 93.3219\n","Epoch 165/1000\n","889/889 [==============================] - 0s 481us/step - loss: 93.6206 - val_loss: 94.5927\n","Epoch 166/1000\n","889/889 [==============================] - 0s 467us/step - loss: 94.3510 - val_loss: 93.2339\n","Epoch 167/1000\n","889/889 [==============================] - 0s 473us/step - loss: 93.1453 - val_loss: 97.3351\n","Epoch 168/1000\n","889/889 [==============================] - 0s 479us/step - loss: 94.0807 - val_loss: 93.1473\n","Epoch 169/1000\n","889/889 [==============================] - 0s 472us/step - loss: 93.6829 - val_loss: 93.0644\n","Epoch 170/1000\n","889/889 [==============================] - 0s 471us/step - loss: 93.0500 - val_loss: 95.5291\n","Epoch 171/1000\n","889/889 [==============================] - 0s 481us/step - loss: 93.0302 - val_loss: 93.2138\n","Epoch 172/1000\n","889/889 [==============================] - 0s 504us/step - loss: 93.5941 - val_loss: 94.5073\n","Epoch 173/1000\n","889/889 [==============================] - 0s 466us/step - loss: 93.8528 - val_loss: 93.5572\n","Epoch 174/1000\n","889/889 [==============================] - 0s 475us/step - loss: 93.3866 - val_loss: 93.0829\n","Epoch 175/1000\n","889/889 [==============================] - 0s 478us/step - loss: 93.4788 - val_loss: 97.1891\n","Epoch 176/1000\n","889/889 [==============================] - 0s 461us/step - loss: 94.3554 - val_loss: 93.0575\n","Epoch 177/1000\n","889/889 [==============================] - 0s 477us/step - loss: 93.6844 - val_loss: 93.1665\n","Epoch 178/1000\n","889/889 [==============================] - 0s 476us/step - loss: 95.0707 - val_loss: 95.9268\n","Epoch 179/1000\n","889/889 [==============================] - 0s 473us/step - loss: 94.3511 - val_loss: 94.8620\n","Epoch 180/1000\n","889/889 [==============================] - 0s 497us/step - loss: 94.2608 - val_loss: 93.0994\n","Epoch 181/1000\n","889/889 [==============================] - 0s 482us/step - loss: 93.3310 - val_loss: 97.0764\n","Epoch 182/1000\n","889/889 [==============================] - 0s 486us/step - loss: 95.4775 - val_loss: 94.8159\n","Epoch 183/1000\n","889/889 [==============================] - 0s 486us/step - loss: 93.8164 - val_loss: 92.5488\n","Epoch 184/1000\n","889/889 [==============================] - 0s 481us/step - loss: 94.4064 - val_loss: 94.4255\n","Epoch 185/1000\n","889/889 [==============================] - 0s 465us/step - loss: 92.8164 - val_loss: 93.6443\n","Epoch 186/1000\n","889/889 [==============================] - 0s 471us/step - loss: 97.9006 - val_loss: 89.4050\n","Epoch 187/1000\n","889/889 [==============================] - 0s 476us/step - loss: 98.0157 - val_loss: 90.6357\n","Epoch 188/1000\n","889/889 [==============================] - 0s 468us/step - loss: 94.7060 - val_loss: 93.9947\n","Epoch 189/1000\n","889/889 [==============================] - 0s 485us/step - loss: 94.6141 - val_loss: 92.6049\n","Epoch 190/1000\n","889/889 [==============================] - 0s 476us/step - loss: 93.7969 - val_loss: 92.9776\n","Epoch 191/1000\n","889/889 [==============================] - 0s 472us/step - loss: 93.4389 - val_loss: 93.6769\n","Epoch 192/1000\n","889/889 [==============================] - 0s 472us/step - loss: 94.1903 - val_loss: 93.0702\n","Epoch 193/1000\n","889/889 [==============================] - 0s 470us/step - loss: 93.7757 - val_loss: 92.3384\n","Epoch 194/1000\n","889/889 [==============================] - 0s 484us/step - loss: 95.0923 - val_loss: 93.3411\n","Epoch 195/1000\n","889/889 [==============================] - 0s 477us/step - loss: 93.0743 - val_loss: 93.9133\n","Epoch 196/1000\n","889/889 [==============================] - 0s 485us/step - loss: 95.3208 - val_loss: 94.4362\n","Epoch 197/1000\n","889/889 [==============================] - 0s 464us/step - loss: 92.9091 - val_loss: 91.2380\n","Epoch 198/1000\n","889/889 [==============================] - 0s 468us/step - loss: 96.4079 - val_loss: 93.0998\n","Epoch 199/1000\n","889/889 [==============================] - 0s 490us/step - loss: 96.0929 - val_loss: 97.3362\n","Epoch 200/1000\n","889/889 [==============================] - 0s 463us/step - loss: 93.2986 - val_loss: 93.2104\n","Epoch 201/1000\n","889/889 [==============================] - 0s 479us/step - loss: 93.2860 - val_loss: 92.8354\n","Epoch 202/1000\n","889/889 [==============================] - 0s 458us/step - loss: 93.0174 - val_loss: 93.9632\n","Epoch 203/1000\n","889/889 [==============================] - 0s 472us/step - loss: 92.7603 - val_loss: 91.9844\n","Epoch 204/1000\n","889/889 [==============================] - 0s 479us/step - loss: 93.8393 - val_loss: 93.1525\n","Epoch 205/1000\n","889/889 [==============================] - 0s 483us/step - loss: 92.2452 - val_loss: 95.5480\n","Epoch 206/1000\n","889/889 [==============================] - 0s 473us/step - loss: 94.4192 - val_loss: 93.1954\n","Epoch 207/1000\n","889/889 [==============================] - 0s 469us/step - loss: 97.1324 - val_loss: 90.2196\n","Epoch 208/1000\n","889/889 [==============================] - 0s 477us/step - loss: 98.6779 - val_loss: 92.5082\n","Epoch 209/1000\n","889/889 [==============================] - 0s 486us/step - loss: 96.1751 - val_loss: 96.0461\n","Epoch 210/1000\n","889/889 [==============================] - 0s 473us/step - loss: 94.1124 - val_loss: 93.4922\n","Epoch 211/1000\n","889/889 [==============================] - 0s 473us/step - loss: 93.3074 - val_loss: 92.3902\n","Epoch 212/1000\n","889/889 [==============================] - 0s 469us/step - loss: 92.9533 - val_loss: 95.4724\n","Epoch 213/1000\n","889/889 [==============================] - 0s 493us/step - loss: 93.3160 - val_loss: 92.2346\n","Epoch 214/1000\n","889/889 [==============================] - 0s 476us/step - loss: 94.1868 - val_loss: 92.4388\n","Epoch 215/1000\n","889/889 [==============================] - 0s 481us/step - loss: 94.1171 - val_loss: 94.9734\n","Epoch 216/1000\n","889/889 [==============================] - 0s 486us/step - loss: 93.4383 - val_loss: 97.7562\n","Epoch 217/1000\n","889/889 [==============================] - 0s 477us/step - loss: 94.9791 - val_loss: 95.9739\n","Epoch 218/1000\n","889/889 [==============================] - 0s 472us/step - loss: 94.5261 - val_loss: 94.2390\n","Epoch 219/1000\n","889/889 [==============================] - 0s 469us/step - loss: 92.7079 - val_loss: 93.5333\n","Epoch 220/1000\n","889/889 [==============================] - 0s 472us/step - loss: 93.5788 - val_loss: 93.6738\n","Epoch 221/1000\n","889/889 [==============================] - 0s 476us/step - loss: 92.7851 - val_loss: 96.8406\n","Epoch 222/1000\n","889/889 [==============================] - 0s 475us/step - loss: 93.1693 - val_loss: 94.8092\n","Epoch 223/1000\n","889/889 [==============================] - 0s 477us/step - loss: 93.2130 - val_loss: 94.3601\n","Epoch 224/1000\n","889/889 [==============================] - 0s 472us/step - loss: 93.8513 - val_loss: 94.2561\n","Epoch 225/1000\n","889/889 [==============================] - 0s 472us/step - loss: 93.1249 - val_loss: 93.7385\n","Epoch 226/1000\n","889/889 [==============================] - 0s 468us/step - loss: 92.9881 - val_loss: 94.4077\n","Epoch 227/1000\n","889/889 [==============================] - 0s 483us/step - loss: 92.6976 - val_loss: 93.5345\n","Epoch 228/1000\n","889/889 [==============================] - 0s 473us/step - loss: 92.3681 - val_loss: 94.5703\n","Epoch 229/1000\n","889/889 [==============================] - 0s 468us/step - loss: 93.0471 - val_loss: 93.5001\n","Epoch 230/1000\n","889/889 [==============================] - 0s 479us/step - loss: 92.7967 - val_loss: 94.1634\n","Epoch 231/1000\n","889/889 [==============================] - 0s 477us/step - loss: 92.2404 - val_loss: 94.6172\n","Epoch 232/1000\n","889/889 [==============================] - 0s 479us/step - loss: 93.7685 - val_loss: 95.1527\n","Epoch 233/1000\n","889/889 [==============================] - 0s 492us/step - loss: 93.7009 - val_loss: 92.7411\n","Epoch 234/1000\n","889/889 [==============================] - 0s 484us/step - loss: 93.9216 - val_loss: 93.6490\n","Epoch 235/1000\n","889/889 [==============================] - 0s 495us/step - loss: 92.9489 - val_loss: 91.5812\n","Epoch 236/1000\n","889/889 [==============================] - 0s 488us/step - loss: 95.2904 - val_loss: 92.0708\n","Epoch 237/1000\n","889/889 [==============================] - 0s 500us/step - loss: 93.8594 - val_loss: 95.3413\n","Epoch 238/1000\n","889/889 [==============================] - 0s 513us/step - loss: 93.5861 - val_loss: 95.9017\n","Epoch 239/1000\n","889/889 [==============================] - 0s 509us/step - loss: 93.9450 - val_loss: 93.8526\n","Epoch 240/1000\n","889/889 [==============================] - 0s 510us/step - loss: 92.4334 - val_loss: 93.6156\n","Epoch 241/1000\n","889/889 [==============================] - 0s 489us/step - loss: 92.3905 - val_loss: 93.2289\n","Epoch 242/1000\n","889/889 [==============================] - 0s 505us/step - loss: 92.5924 - val_loss: 94.2563\n","Epoch 243/1000\n","889/889 [==============================] - 0s 488us/step - loss: 92.6489 - val_loss: 93.5890\n","Epoch 244/1000\n","889/889 [==============================] - 0s 523us/step - loss: 93.0620 - val_loss: 95.6012\n","Epoch 245/1000\n","889/889 [==============================] - 0s 502us/step - loss: 93.6494 - val_loss: 96.9318\n","Epoch 246/1000\n","889/889 [==============================] - 0s 506us/step - loss: 95.3051 - val_loss: 93.8019\n","Epoch 247/1000\n","889/889 [==============================] - 0s 515us/step - loss: 94.1949 - val_loss: 91.8502\n","Epoch 248/1000\n","889/889 [==============================] - 0s 504us/step - loss: 95.5156 - val_loss: 93.8018\n","Epoch 249/1000\n","889/889 [==============================] - 0s 507us/step - loss: 94.4759 - val_loss: 94.6414\n","Epoch 250/1000\n","889/889 [==============================] - 0s 510us/step - loss: 92.2483 - val_loss: 93.6836\n","Epoch 251/1000\n","889/889 [==============================] - 0s 523us/step - loss: 93.2491 - val_loss: 93.0937\n","Epoch 252/1000\n","889/889 [==============================] - 0s 511us/step - loss: 92.4729 - val_loss: 91.9988\n","Epoch 253/1000\n","889/889 [==============================] - 0s 511us/step - loss: 92.9490 - val_loss: 94.1119\n","Epoch 254/1000\n","889/889 [==============================] - 0s 502us/step - loss: 92.8745 - val_loss: 94.3805\n","Epoch 255/1000\n","889/889 [==============================] - 0s 506us/step - loss: 92.8830 - val_loss: 93.9722\n","Epoch 256/1000\n","889/889 [==============================] - 0s 518us/step - loss: 92.2221 - val_loss: 93.2414\n","Epoch 257/1000\n","889/889 [==============================] - 0s 498us/step - loss: 92.4424 - val_loss: 92.8386\n","Epoch 258/1000\n","889/889 [==============================] - 0s 512us/step - loss: 92.7502 - val_loss: 93.1481\n","Epoch 259/1000\n","889/889 [==============================] - 0s 502us/step - loss: 93.9907 - val_loss: 95.2400\n","Epoch 260/1000\n","889/889 [==============================] - 0s 521us/step - loss: 93.0381 - val_loss: 93.0702\n","Epoch 261/1000\n","889/889 [==============================] - 0s 503us/step - loss: 92.6132 - val_loss: 95.1100\n","Epoch 262/1000\n","889/889 [==============================] - 0s 518us/step - loss: 92.2474 - val_loss: 94.4388\n","Epoch 263/1000\n","889/889 [==============================] - 0s 500us/step - loss: 92.6297 - val_loss: 94.6049\n","Epoch 264/1000\n","889/889 [==============================] - 0s 494us/step - loss: 93.6955 - val_loss: 95.1099\n","Epoch 265/1000\n","889/889 [==============================] - 0s 509us/step - loss: 92.2158 - val_loss: 96.3386\n","Epoch 266/1000\n","889/889 [==============================] - 0s 495us/step - loss: 92.1200 - val_loss: 92.9385\n","Epoch 267/1000\n","889/889 [==============================] - 0s 499us/step - loss: 92.6596 - val_loss: 91.8196\n","Epoch 268/1000\n","889/889 [==============================] - 0s 496us/step - loss: 92.4158 - val_loss: 92.1892\n","Epoch 269/1000\n","889/889 [==============================] - 0s 516us/step - loss: 92.0115 - val_loss: 92.7798\n","Epoch 270/1000\n","889/889 [==============================] - 0s 511us/step - loss: 92.2346 - val_loss: 94.4655\n","Epoch 271/1000\n","889/889 [==============================] - 0s 526us/step - loss: 92.7275 - val_loss: 94.5467\n","Epoch 272/1000\n","889/889 [==============================] - 0s 522us/step - loss: 93.1100 - val_loss: 95.0810\n","Epoch 273/1000\n","889/889 [==============================] - 0s 526us/step - loss: 91.6656 - val_loss: 93.3199\n","Epoch 274/1000\n","889/889 [==============================] - 0s 530us/step - loss: 92.9707 - val_loss: 93.1877\n","Epoch 275/1000\n","889/889 [==============================] - 0s 510us/step - loss: 92.0623 - val_loss: 94.6488\n","Epoch 276/1000\n","889/889 [==============================] - 0s 541us/step - loss: 92.1539 - val_loss: 94.6313\n","Epoch 277/1000\n","889/889 [==============================] - 0s 516us/step - loss: 92.6301 - val_loss: 96.9192\n","Epoch 278/1000\n","889/889 [==============================] - 0s 498us/step - loss: 92.5476 - val_loss: 94.3597\n","Epoch 279/1000\n","889/889 [==============================] - 0s 475us/step - loss: 91.8872 - val_loss: 93.6523\n","Epoch 280/1000\n","889/889 [==============================] - 0s 461us/step - loss: 92.1666 - val_loss: 94.4063\n","Epoch 281/1000\n","889/889 [==============================] - 0s 469us/step - loss: 92.3472 - val_loss: 97.8755\n","Epoch 282/1000\n","889/889 [==============================] - 0s 470us/step - loss: 94.2826 - val_loss: 93.0132\n","Epoch 283/1000\n","889/889 [==============================] - 0s 479us/step - loss: 92.5321 - val_loss: 94.4231\n","Epoch 284/1000\n","889/889 [==============================] - 0s 464us/step - loss: 94.0135 - val_loss: 93.6164\n","Epoch 285/1000\n","889/889 [==============================] - 0s 487us/step - loss: 93.6996 - val_loss: 92.7820\n","Epoch 286/1000\n","889/889 [==============================] - 0s 465us/step - loss: 94.2412 - val_loss: 91.1719\n","Epoch 287/1000\n","889/889 [==============================] - 0s 472us/step - loss: 93.0467 - val_loss: 93.4015\n","Epoch 288/1000\n","889/889 [==============================] - 0s 477us/step - loss: 92.6823 - val_loss: 93.7157\n","Epoch 289/1000\n","889/889 [==============================] - 0s 468us/step - loss: 92.3388 - val_loss: 92.7777\n","Epoch 290/1000\n","889/889 [==============================] - 0s 477us/step - loss: 92.1433 - val_loss: 92.9449\n","Epoch 291/1000\n","889/889 [==============================] - 0s 470us/step - loss: 92.0858 - val_loss: 93.6243\n","Epoch 292/1000\n","889/889 [==============================] - 0s 461us/step - loss: 91.8313 - val_loss: 94.8476\n","Epoch 293/1000\n","889/889 [==============================] - 0s 476us/step - loss: 92.7657 - val_loss: 93.7172\n","Epoch 294/1000\n","889/889 [==============================] - 0s 473us/step - loss: 92.4289 - val_loss: 94.1933\n","Epoch 295/1000\n","889/889 [==============================] - 0s 480us/step - loss: 92.9686 - val_loss: 95.3214\n","Epoch 296/1000\n","889/889 [==============================] - 0s 457us/step - loss: 92.5008 - val_loss: 91.5107\n","Epoch 297/1000\n","889/889 [==============================] - 0s 467us/step - loss: 93.5989 - val_loss: 92.4180\n","Epoch 298/1000\n","889/889 [==============================] - 0s 471us/step - loss: 92.4366 - val_loss: 94.0011\n","Epoch 299/1000\n","889/889 [==============================] - 0s 472us/step - loss: 92.1205 - val_loss: 93.3815\n","Epoch 300/1000\n","889/889 [==============================] - 0s 483us/step - loss: 92.2882 - val_loss: 93.3501\n","Epoch 301/1000\n","889/889 [==============================] - 0s 466us/step - loss: 91.6517 - val_loss: 92.7198\n","Epoch 302/1000\n","889/889 [==============================] - 0s 474us/step - loss: 91.6680 - val_loss: 93.1531\n","Epoch 303/1000\n","889/889 [==============================] - 0s 465us/step - loss: 92.0038 - val_loss: 95.7918\n","Epoch 304/1000\n","889/889 [==============================] - 0s 475us/step - loss: 92.3201 - val_loss: 93.9319\n","Epoch 305/1000\n","889/889 [==============================] - 0s 482us/step - loss: 91.0319 - val_loss: 93.2507\n","Epoch 306/1000\n","889/889 [==============================] - 0s 470us/step - loss: 92.0854 - val_loss: 92.8964\n","Epoch 307/1000\n","889/889 [==============================] - 0s 485us/step - loss: 92.3386 - val_loss: 93.3279\n","Epoch 308/1000\n","889/889 [==============================] - 0s 467us/step - loss: 92.9026 - val_loss: 94.5445\n","Epoch 309/1000\n","889/889 [==============================] - 0s 463us/step - loss: 91.1803 - val_loss: 94.1104\n","Epoch 310/1000\n","889/889 [==============================] - 0s 466us/step - loss: 92.5469 - val_loss: 92.8539\n","Epoch 311/1000\n","889/889 [==============================] - 0s 475us/step - loss: 92.4274 - val_loss: 95.1215\n","Epoch 312/1000\n","889/889 [==============================] - 0s 480us/step - loss: 92.2980 - val_loss: 92.2770\n","Epoch 313/1000\n","889/889 [==============================] - 0s 477us/step - loss: 91.8596 - val_loss: 93.1471\n","Epoch 314/1000\n","889/889 [==============================] - 0s 473us/step - loss: 93.5185 - val_loss: 92.1687\n","Epoch 315/1000\n","889/889 [==============================] - 0s 463us/step - loss: 93.3927 - val_loss: 93.3109\n","Epoch 316/1000\n","889/889 [==============================] - 0s 467us/step - loss: 91.8259 - val_loss: 95.7065\n","Epoch 317/1000\n","889/889 [==============================] - 0s 482us/step - loss: 92.8005 - val_loss: 89.5376\n","Epoch 318/1000\n","889/889 [==============================] - 0s 475us/step - loss: 95.4584 - val_loss: 89.4707\n","Epoch 319/1000\n","889/889 [==============================] - 0s 486us/step - loss: 95.5882 - val_loss: 90.0141\n","Epoch 320/1000\n","889/889 [==============================] - 0s 476us/step - loss: 92.1851 - val_loss: 93.1758\n","Epoch 321/1000\n","889/889 [==============================] - 0s 471us/step - loss: 92.8124 - val_loss: 94.2811\n","Epoch 322/1000\n","889/889 [==============================] - 0s 480us/step - loss: 91.2933 - val_loss: 93.6833\n","Epoch 323/1000\n","889/889 [==============================] - 0s 472us/step - loss: 91.7814 - val_loss: 96.9889\n","Epoch 324/1000\n","889/889 [==============================] - 0s 483us/step - loss: 91.6636 - val_loss: 95.3923\n","Epoch 325/1000\n","889/889 [==============================] - 0s 468us/step - loss: 91.4410 - val_loss: 96.3682\n","Epoch 326/1000\n","889/889 [==============================] - 0s 474us/step - loss: 90.7460 - val_loss: 94.5950\n","Epoch 327/1000\n","889/889 [==============================] - 0s 480us/step - loss: 91.1914 - val_loss: 94.0233\n","Epoch 328/1000\n","889/889 [==============================] - 0s 472us/step - loss: 91.0444 - val_loss: 94.0294\n","Epoch 329/1000\n","889/889 [==============================] - 0s 470us/step - loss: 92.2408 - val_loss: 93.3027\n","Epoch 330/1000\n","889/889 [==============================] - 0s 479us/step - loss: 90.4440 - val_loss: 90.1366\n","Epoch 331/1000\n","889/889 [==============================] - 0s 474us/step - loss: 92.3291 - val_loss: 88.7835\n","Epoch 332/1000\n","889/889 [==============================] - 0s 486us/step - loss: 91.8656 - val_loss: 90.4445\n","Epoch 333/1000\n","889/889 [==============================] - 0s 468us/step - loss: 91.0659 - val_loss: 92.0765\n","Epoch 334/1000\n","889/889 [==============================] - 0s 479us/step - loss: 90.5320 - val_loss: 93.1579\n","Epoch 335/1000\n","889/889 [==============================] - 0s 465us/step - loss: 90.0578 - val_loss: 94.1720\n","Epoch 336/1000\n","889/889 [==============================] - 0s 486us/step - loss: 90.2729 - val_loss: 92.8978\n","Epoch 337/1000\n","889/889 [==============================] - 0s 474us/step - loss: 90.6789 - val_loss: 93.5674\n","Epoch 338/1000\n","889/889 [==============================] - 0s 466us/step - loss: 90.3096 - val_loss: 95.0615\n","Epoch 339/1000\n","889/889 [==============================] - 0s 474us/step - loss: 91.7179 - val_loss: 91.8110\n","Epoch 340/1000\n","889/889 [==============================] - 0s 467us/step - loss: 91.0809 - val_loss: 93.0833\n","Epoch 341/1000\n","889/889 [==============================] - 0s 475us/step - loss: 89.8377 - val_loss: 92.6908\n","Epoch 342/1000\n","889/889 [==============================] - 0s 479us/step - loss: 89.7537 - val_loss: 90.8523\n","Epoch 343/1000\n","889/889 [==============================] - 0s 477us/step - loss: 89.9085 - val_loss: 91.5751\n","Epoch 344/1000\n","889/889 [==============================] - 0s 491us/step - loss: 89.5821 - val_loss: 91.2898\n","Epoch 345/1000\n","889/889 [==============================] - 0s 474us/step - loss: 92.1039 - val_loss: 91.8670\n","Epoch 346/1000\n","889/889 [==============================] - 0s 487us/step - loss: 89.9745 - val_loss: 93.3321\n","Epoch 347/1000\n","889/889 [==============================] - 0s 467us/step - loss: 90.8213 - val_loss: 93.9860\n","Epoch 348/1000\n","889/889 [==============================] - 0s 484us/step - loss: 92.2094 - val_loss: 92.4830\n","Epoch 349/1000\n","889/889 [==============================] - 0s 473us/step - loss: 92.8697 - val_loss: 91.2381\n","Epoch 350/1000\n","889/889 [==============================] - 0s 469us/step - loss: 93.1372 - val_loss: 92.1598\n","Epoch 351/1000\n","889/889 [==============================] - 0s 477us/step - loss: 91.8812 - val_loss: 94.7289\n","Epoch 352/1000\n","889/889 [==============================] - 0s 468us/step - loss: 96.7967 - val_loss: 93.4415\n","Epoch 353/1000\n","889/889 [==============================] - 0s 476us/step - loss: 91.0078 - val_loss: 90.5419\n","Epoch 354/1000\n","889/889 [==============================] - 0s 457us/step - loss: 93.1559 - val_loss: 90.8575\n","Epoch 355/1000\n","889/889 [==============================] - 0s 469us/step - loss: 92.2390 - val_loss: 92.6344\n","Epoch 356/1000\n","889/889 [==============================] - 0s 490us/step - loss: 90.9721 - val_loss: 92.9896\n","Epoch 357/1000\n","889/889 [==============================] - 0s 465us/step - loss: 91.0678 - val_loss: 91.7578\n","Epoch 358/1000\n","889/889 [==============================] - 0s 479us/step - loss: 90.8467 - val_loss: 92.7294\n","Epoch 359/1000\n","889/889 [==============================] - 0s 476us/step - loss: 90.3102 - val_loss: 92.7716\n","Epoch 360/1000\n","889/889 [==============================] - 0s 478us/step - loss: 90.8478 - val_loss: 91.1069\n","Epoch 361/1000\n","889/889 [==============================] - 0s 489us/step - loss: 89.5900 - val_loss: 91.8590\n","Epoch 362/1000\n","889/889 [==============================] - 0s 462us/step - loss: 90.3877 - val_loss: 90.3599\n","Epoch 363/1000\n","889/889 [==============================] - 0s 475us/step - loss: 90.0507 - val_loss: 91.4415\n","Epoch 364/1000\n","889/889 [==============================] - 0s 464us/step - loss: 89.2726 - val_loss: 91.5381\n","Epoch 365/1000\n","889/889 [==============================] - 0s 480us/step - loss: 91.4601 - val_loss: 93.0975\n","Epoch 366/1000\n","889/889 [==============================] - 0s 475us/step - loss: 89.8298 - val_loss: 95.2159\n","Epoch 367/1000\n","889/889 [==============================] - 0s 464us/step - loss: 91.6707 - val_loss: 90.3299\n","Epoch 368/1000\n","889/889 [==============================] - 0s 483us/step - loss: 90.9642 - val_loss: 92.3959\n","Epoch 369/1000\n","889/889 [==============================] - 0s 470us/step - loss: 90.0361 - val_loss: 93.9090\n","Epoch 370/1000\n","889/889 [==============================] - 0s 489us/step - loss: 89.0608 - val_loss: 89.9706\n","Epoch 371/1000\n","889/889 [==============================] - 0s 481us/step - loss: 91.2000 - val_loss: 89.6101\n","Epoch 372/1000\n","889/889 [==============================] - 0s 462us/step - loss: 91.4777 - val_loss: 89.5924\n","Epoch 373/1000\n","889/889 [==============================] - 0s 475us/step - loss: 89.1152 - val_loss: 90.1318\n","Epoch 374/1000\n","889/889 [==============================] - 0s 457us/step - loss: 89.6413 - val_loss: 92.5673\n","Epoch 375/1000\n","889/889 [==============================] - 0s 485us/step - loss: 89.5869 - val_loss: 91.1923\n","Epoch 376/1000\n","889/889 [==============================] - 0s 473us/step - loss: 89.6311 - val_loss: 92.0434\n","Epoch 377/1000\n","889/889 [==============================] - 0s 475us/step - loss: 90.4872 - val_loss: 92.6815\n","Epoch 378/1000\n","889/889 [==============================] - 0s 498us/step - loss: 89.6406 - val_loss: 90.9083\n","Epoch 379/1000\n","889/889 [==============================] - 0s 489us/step - loss: 88.1633 - val_loss: 87.7991\n","Epoch 380/1000\n","889/889 [==============================] - 0s 505us/step - loss: 91.1091 - val_loss: 87.3631\n","Epoch 381/1000\n","889/889 [==============================] - 0s 479us/step - loss: 89.1533 - val_loss: 90.3222\n","Epoch 382/1000\n","889/889 [==============================] - 0s 516us/step - loss: 89.6894 - val_loss: 91.6009\n","Epoch 383/1000\n","889/889 [==============================] - 0s 500us/step - loss: 88.9681 - val_loss: 92.9326\n","Epoch 384/1000\n","889/889 [==============================] - 0s 517us/step - loss: 89.7757 - val_loss: 92.6370\n","Epoch 385/1000\n","889/889 [==============================] - 0s 490us/step - loss: 92.9493 - val_loss: 90.5361\n","Epoch 386/1000\n","889/889 [==============================] - 0s 489us/step - loss: 91.6166 - val_loss: 91.0915\n","Epoch 387/1000\n","889/889 [==============================] - 0s 484us/step - loss: 89.5037 - val_loss: 92.5576\n","Epoch 388/1000\n","889/889 [==============================] - 0s 490us/step - loss: 89.6459 - val_loss: 88.5042\n","Epoch 389/1000\n","889/889 [==============================] - 0s 485us/step - loss: 90.9865 - val_loss: 88.5826\n","Epoch 390/1000\n","889/889 [==============================] - 0s 488us/step - loss: 89.8671 - val_loss: 89.5672\n","Epoch 391/1000\n","889/889 [==============================] - 0s 500us/step - loss: 89.7958 - val_loss: 90.3510\n","Epoch 392/1000\n","889/889 [==============================] - 0s 503us/step - loss: 89.7910 - val_loss: 93.6283\n","Epoch 393/1000\n","889/889 [==============================] - 0s 506us/step - loss: 90.4488 - val_loss: 95.6852\n","Epoch 394/1000\n","889/889 [==============================] - 0s 504us/step - loss: 89.4734 - val_loss: 92.2173\n","Epoch 395/1000\n","889/889 [==============================] - 0s 516us/step - loss: 88.8760 - val_loss: 90.8475\n","Epoch 396/1000\n","889/889 [==============================] - 0s 500us/step - loss: 88.3497 - val_loss: 89.5384\n","Epoch 397/1000\n","889/889 [==============================] - 0s 485us/step - loss: 88.4619 - val_loss: 93.1968\n","Epoch 398/1000\n","889/889 [==============================] - 0s 491us/step - loss: 90.7670 - val_loss: 95.1098\n","Epoch 399/1000\n","889/889 [==============================] - 0s 482us/step - loss: 94.6682 - val_loss: 91.1174\n","Epoch 400/1000\n","889/889 [==============================] - 0s 490us/step - loss: 89.7384 - val_loss: 91.1230\n","Epoch 401/1000\n","889/889 [==============================] - 0s 512us/step - loss: 94.5887 - val_loss: 93.6217\n","Epoch 402/1000\n","889/889 [==============================] - 0s 511us/step - loss: 89.0300 - val_loss: 92.5187\n","Epoch 403/1000\n","889/889 [==============================] - 0s 510us/step - loss: 91.6678 - val_loss: 96.3380\n","Epoch 404/1000\n","889/889 [==============================] - 0s 488us/step - loss: 89.5318 - val_loss: 90.7361\n","Epoch 405/1000\n","889/889 [==============================] - 0s 499us/step - loss: 89.7474 - val_loss: 93.5749\n","Epoch 406/1000\n","889/889 [==============================] - 0s 492us/step - loss: 89.2440 - val_loss: 94.6292\n","Epoch 407/1000\n","889/889 [==============================] - 0s 486us/step - loss: 91.8590 - val_loss: 93.1432\n","Epoch 408/1000\n","889/889 [==============================] - 0s 493us/step - loss: 88.0012 - val_loss: 90.7939\n","Epoch 409/1000\n","889/889 [==============================] - 0s 494us/step - loss: 89.2665 - val_loss: 88.9123\n","Epoch 410/1000\n","889/889 [==============================] - 0s 499us/step - loss: 88.4653 - val_loss: 89.0353\n","Epoch 411/1000\n","889/889 [==============================] - 0s 492us/step - loss: 92.8218 - val_loss: 89.2547\n","Epoch 412/1000\n","889/889 [==============================] - 0s 504us/step - loss: 91.4625 - val_loss: 94.1864\n","Epoch 413/1000\n","889/889 [==============================] - 0s 498us/step - loss: 89.8896 - val_loss: 90.5951\n","Epoch 414/1000\n","889/889 [==============================] - 0s 491us/step - loss: 90.3885 - val_loss: 88.9393\n","Epoch 415/1000\n","889/889 [==============================] - 0s 503us/step - loss: 90.1877 - val_loss: 89.5693\n","Epoch 416/1000\n","889/889 [==============================] - 0s 480us/step - loss: 88.2130 - val_loss: 92.6630\n","Epoch 417/1000\n","889/889 [==============================] - 0s 489us/step - loss: 90.3911 - val_loss: 91.5058\n","Epoch 418/1000\n","889/889 [==============================] - 0s 491us/step - loss: 88.6667 - val_loss: 88.4263\n","Epoch 419/1000\n","889/889 [==============================] - 0s 498us/step - loss: 90.4071 - val_loss: 89.2482\n","Epoch 420/1000\n","889/889 [==============================] - 0s 486us/step - loss: 89.5791 - val_loss: 87.4632\n","Epoch 421/1000\n","889/889 [==============================] - 0s 491us/step - loss: 88.7986 - val_loss: 89.9229\n","Epoch 422/1000\n","889/889 [==============================] - 0s 496us/step - loss: 88.9016 - val_loss: 90.4422\n","Epoch 423/1000\n","889/889 [==============================] - 0s 490us/step - loss: 89.0180 - val_loss: 91.9736\n","Epoch 424/1000\n","889/889 [==============================] - 0s 504us/step - loss: 90.6498 - val_loss: 92.0397\n","Epoch 425/1000\n","889/889 [==============================] - 0s 487us/step - loss: 89.2604 - val_loss: 92.2807\n","Epoch 426/1000\n","889/889 [==============================] - 0s 504us/step - loss: 90.1345 - val_loss: 90.5418\n","Epoch 427/1000\n","889/889 [==============================] - 0s 490us/step - loss: 88.4466 - val_loss: 89.0450\n","Epoch 428/1000\n","889/889 [==============================] - 0s 494us/step - loss: 89.5042 - val_loss: 89.7618\n","Epoch 429/1000\n","889/889 [==============================] - 0s 495us/step - loss: 89.1988 - val_loss: 89.4459\n","Epoch 430/1000\n","889/889 [==============================] - 0s 490us/step - loss: 88.5600 - val_loss: 91.9659\n","Epoch 431/1000\n","889/889 [==============================] - 0s 503us/step - loss: 89.0323 - val_loss: 91.6659\n","Epoch 432/1000\n","889/889 [==============================] - 0s 486us/step - loss: 89.5107 - val_loss: 92.5368\n","Epoch 433/1000\n","889/889 [==============================] - 0s 491us/step - loss: 89.8203 - val_loss: 91.3534\n","Epoch 434/1000\n","889/889 [==============================] - 0s 483us/step - loss: 87.9568 - val_loss: 88.9538\n","Epoch 435/1000\n","889/889 [==============================] - 0s 492us/step - loss: 87.5548 - val_loss: 90.4647\n","Epoch 436/1000\n","889/889 [==============================] - 0s 493us/step - loss: 87.8063 - val_loss: 90.2595\n","Epoch 437/1000\n","889/889 [==============================] - 0s 494us/step - loss: 87.2742 - val_loss: 92.6715\n","Epoch 438/1000\n","889/889 [==============================] - 0s 499us/step - loss: 87.7799 - val_loss: 92.0826\n","Epoch 439/1000\n","889/889 [==============================] - 0s 487us/step - loss: 87.8499 - val_loss: 92.4320\n","Epoch 440/1000\n","889/889 [==============================] - 0s 502us/step - loss: 86.8805 - val_loss: 95.8661\n","Epoch 441/1000\n","889/889 [==============================] - 0s 481us/step - loss: 86.8898 - val_loss: 90.0854\n","Epoch 442/1000\n","889/889 [==============================] - 0s 494us/step - loss: 88.4481 - val_loss: 92.0726\n","Epoch 443/1000\n","889/889 [==============================] - 0s 494us/step - loss: 86.5597 - val_loss: 90.8062\n","Epoch 444/1000\n","889/889 [==============================] - 0s 480us/step - loss: 88.3710 - val_loss: 91.2526\n","Epoch 445/1000\n","889/889 [==============================] - 0s 505us/step - loss: 87.7523 - val_loss: 92.8548\n","Epoch 446/1000\n","889/889 [==============================] - 0s 491us/step - loss: 86.9055 - val_loss: 90.8710\n","Epoch 447/1000\n","889/889 [==============================] - 0s 515us/step - loss: 86.7607 - val_loss: 92.7234\n","Epoch 448/1000\n","889/889 [==============================] - 0s 489us/step - loss: 87.5000 - val_loss: 92.9660\n","Epoch 449/1000\n","889/889 [==============================] - 0s 486us/step - loss: 86.1348 - val_loss: 90.0041\n","Epoch 450/1000\n","889/889 [==============================] - 0s 492us/step - loss: 87.1394 - val_loss: 92.5615\n","Epoch 451/1000\n","889/889 [==============================] - 0s 489us/step - loss: 85.7428 - val_loss: 91.6172\n","Epoch 452/1000\n","889/889 [==============================] - 0s 503us/step - loss: 86.2635 - val_loss: 90.9818\n","Epoch 453/1000\n","889/889 [==============================] - 0s 488us/step - loss: 87.3479 - val_loss: 96.7083\n","Epoch 454/1000\n","889/889 [==============================] - 0s 505us/step - loss: 95.6103 - val_loss: 93.3954\n","Epoch 455/1000\n","889/889 [==============================] - 0s 482us/step - loss: 92.7330 - val_loss: 89.1099\n","Epoch 456/1000\n","889/889 [==============================] - 0s 496us/step - loss: 92.9640 - val_loss: 89.4797\n","Epoch 457/1000\n","889/889 [==============================] - 0s 500us/step - loss: 92.5496 - val_loss: 91.8866\n","Epoch 458/1000\n","889/889 [==============================] - 0s 485us/step - loss: 93.1565 - val_loss: 93.8524\n","Epoch 459/1000\n","889/889 [==============================] - 0s 500us/step - loss: 90.6124 - val_loss: 99.0726\n","Epoch 460/1000\n","889/889 [==============================] - 0s 491us/step - loss: 91.2717 - val_loss: 93.4597\n","Epoch 461/1000\n","889/889 [==============================] - 0s 500us/step - loss: 89.8274 - val_loss: 92.7486\n","Epoch 462/1000\n","889/889 [==============================] - 0s 500us/step - loss: 89.1995 - val_loss: 94.6101\n","Epoch 463/1000\n","889/889 [==============================] - 0s 485us/step - loss: 89.7097 - val_loss: 94.2202\n","Epoch 464/1000\n","889/889 [==============================] - 0s 487us/step - loss: 88.5570 - val_loss: 91.2994\n","Epoch 465/1000\n","889/889 [==============================] - 0s 478us/step - loss: 88.4707 - val_loss: 89.6182\n","Epoch 466/1000\n","889/889 [==============================] - 0s 483us/step - loss: 87.8538 - val_loss: 91.2553\n","Epoch 467/1000\n","889/889 [==============================] - 0s 464us/step - loss: 87.3557 - val_loss: 91.1043\n","Epoch 468/1000\n","889/889 [==============================] - 0s 479us/step - loss: 88.4513 - val_loss: 91.4770\n","Epoch 469/1000\n","889/889 [==============================] - 0s 477us/step - loss: 88.1413 - val_loss: 90.7149\n","Epoch 470/1000\n","889/889 [==============================] - 0s 470us/step - loss: 89.3580 - val_loss: 90.4260\n","Epoch 471/1000\n","889/889 [==============================] - 0s 485us/step - loss: 86.5765 - val_loss: 93.1718\n","Epoch 472/1000\n","889/889 [==============================] - 0s 464us/step - loss: 87.0702 - val_loss: 93.4747\n","Epoch 473/1000\n","889/889 [==============================] - 0s 492us/step - loss: 86.4651 - val_loss: 90.2312\n","Epoch 474/1000\n","889/889 [==============================] - 0s 473us/step - loss: 87.4876 - val_loss: 91.4330\n","Epoch 475/1000\n","889/889 [==============================] - 0s 496us/step - loss: 86.5158 - val_loss: 92.7111\n","Epoch 476/1000\n","889/889 [==============================] - 0s 503us/step - loss: 86.0160 - val_loss: 92.3518\n","Epoch 477/1000\n","889/889 [==============================] - 0s 488us/step - loss: 85.3123 - val_loss: 90.1947\n","Epoch 478/1000\n","889/889 [==============================] - 0s 498us/step - loss: 85.9690 - val_loss: 93.4989\n","Epoch 479/1000\n","889/889 [==============================] - 0s 489us/step - loss: 86.7787 - val_loss: 95.3186\n","Epoch 480/1000\n","889/889 [==============================] - 0s 510us/step - loss: 86.5264 - val_loss: 91.3239\n","Epoch 481/1000\n","889/889 [==============================] - 0s 490us/step - loss: 84.7927 - val_loss: 93.6770\n","Epoch 482/1000\n","889/889 [==============================] - 0s 492us/step - loss: 85.7288 - val_loss: 93.3151\n","Epoch 483/1000\n","889/889 [==============================] - 0s 496us/step - loss: 84.2226 - val_loss: 93.3356\n","Epoch 484/1000\n","889/889 [==============================] - 0s 486us/step - loss: 86.9309 - val_loss: 93.6386\n","Epoch 485/1000\n","889/889 [==============================] - 0s 495us/step - loss: 85.1947 - val_loss: 90.0801\n","Epoch 486/1000\n","889/889 [==============================] - 0s 486us/step - loss: 88.0452 - val_loss: 92.3327\n","Epoch 487/1000\n","889/889 [==============================] - 0s 506us/step - loss: 86.7925 - val_loss: 96.9881\n","Epoch 488/1000\n","889/889 [==============================] - 0s 488us/step - loss: 91.5651 - val_loss: 94.0206\n","Epoch 489/1000\n","889/889 [==============================] - 0s 482us/step - loss: 86.9395 - val_loss: 86.9543\n","Epoch 490/1000\n","889/889 [==============================] - 0s 499us/step - loss: 89.6052 - val_loss: 85.8175\n","Epoch 491/1000\n","889/889 [==============================] - 0s 496us/step - loss: 90.8892 - val_loss: 93.5487\n","Epoch 492/1000\n","889/889 [==============================] - 0s 500us/step - loss: 91.5652 - val_loss: 90.6975\n","Epoch 493/1000\n","889/889 [==============================] - 0s 490us/step - loss: 92.7265 - val_loss: 95.0455\n","Epoch 494/1000\n","889/889 [==============================] - 0s 493us/step - loss: 92.7028 - val_loss: 90.7940\n","Epoch 495/1000\n","889/889 [==============================] - 0s 496us/step - loss: 90.2360 - val_loss: 87.6184\n","Epoch 496/1000\n","889/889 [==============================] - 0s 487us/step - loss: 92.3425 - val_loss: 89.6060\n","Epoch 497/1000\n","889/889 [==============================] - 0s 500us/step - loss: 88.9844 - val_loss: 88.4804\n","Epoch 498/1000\n","889/889 [==============================] - 0s 487us/step - loss: 90.1987 - val_loss: 85.8529\n","Epoch 499/1000\n","889/889 [==============================] - 0s 502us/step - loss: 89.7966 - val_loss: 89.3315\n","Epoch 500/1000\n","889/889 [==============================] - 0s 487us/step - loss: 88.1351 - val_loss: 91.0072\n","Epoch 501/1000\n","889/889 [==============================] - 0s 500us/step - loss: 86.0059 - val_loss: 91.0986\n","Epoch 502/1000\n","889/889 [==============================] - 0s 487us/step - loss: 84.6916 - val_loss: 90.6637\n","Epoch 503/1000\n","889/889 [==============================] - 0s 491us/step - loss: 84.8826 - val_loss: 92.4474\n","Epoch 504/1000\n","889/889 [==============================] - 0s 495us/step - loss: 86.5739 - val_loss: 92.5511\n","Epoch 505/1000\n","889/889 [==============================] - 0s 491us/step - loss: 87.2601 - val_loss: 92.8114\n","Epoch 506/1000\n","889/889 [==============================] - 0s 503us/step - loss: 84.1098 - val_loss: 92.9908\n","Epoch 507/1000\n","889/889 [==============================] - 0s 495us/step - loss: 86.5831 - val_loss: 88.4170\n","Epoch 508/1000\n","889/889 [==============================] - 0s 513us/step - loss: 86.3909 - val_loss: 88.9020\n","Epoch 509/1000\n","889/889 [==============================] - 0s 487us/step - loss: 84.9222 - val_loss: 90.9709\n","Epoch 510/1000\n","889/889 [==============================] - 0s 483us/step - loss: 84.8672 - val_loss: 91.8441\n","Epoch 511/1000\n","889/889 [==============================] - 0s 495us/step - loss: 84.5447 - val_loss: 89.8399\n","Epoch 512/1000\n","889/889 [==============================] - 0s 490us/step - loss: 84.8031 - val_loss: 91.6617\n","Epoch 513/1000\n","889/889 [==============================] - 0s 498us/step - loss: 84.3085 - val_loss: 92.9075\n","Epoch 514/1000\n","889/889 [==============================] - 0s 488us/step - loss: 85.1329 - val_loss: 91.9398\n","Epoch 515/1000\n","889/889 [==============================] - 0s 499us/step - loss: 84.8680 - val_loss: 91.8651\n","Epoch 516/1000\n","889/889 [==============================] - 0s 483us/step - loss: 85.4680 - val_loss: 92.8027\n","Epoch 517/1000\n","889/889 [==============================] - 0s 487us/step - loss: 86.5312 - val_loss: 88.3621\n","Epoch 518/1000\n","889/889 [==============================] - 0s 499us/step - loss: 86.7868 - val_loss: 98.3456\n","Epoch 519/1000\n","889/889 [==============================] - 0s 479us/step - loss: 90.4524 - val_loss: 101.0551\n","Epoch 520/1000\n","889/889 [==============================] - 0s 500us/step - loss: 95.4067 - val_loss: 93.0878\n","Epoch 521/1000\n","889/889 [==============================] - 0s 489us/step - loss: 89.9168 - val_loss: 90.5393\n","Epoch 522/1000\n","889/889 [==============================] - 0s 508us/step - loss: 90.3049 - val_loss: 88.8325\n","Epoch 523/1000\n","889/889 [==============================] - 0s 479us/step - loss: 89.8475 - val_loss: 88.1950\n","Epoch 524/1000\n","889/889 [==============================] - 0s 486us/step - loss: 90.2605 - val_loss: 89.3611\n","Epoch 525/1000\n","889/889 [==============================] - 0s 506us/step - loss: 87.4688 - val_loss: 90.3015\n","Epoch 526/1000\n","889/889 [==============================] - 0s 481us/step - loss: 86.6421 - val_loss: 92.4026\n","Epoch 527/1000\n","889/889 [==============================] - 0s 500us/step - loss: 87.3294 - val_loss: 90.2047\n","Epoch 528/1000\n","889/889 [==============================] - 0s 484us/step - loss: 86.4947 - val_loss: 90.8357\n","Epoch 529/1000\n","889/889 [==============================] - 0s 510us/step - loss: 85.7558 - val_loss: 92.6057\n","Epoch 530/1000\n","889/889 [==============================] - 0s 492us/step - loss: 86.5418 - val_loss: 90.7574\n","Epoch 531/1000\n","889/889 [==============================] - 0s 487us/step - loss: 85.0263 - val_loss: 90.1621\n","Epoch 532/1000\n","889/889 [==============================] - 0s 499us/step - loss: 86.2293 - val_loss: 89.6884\n","Epoch 533/1000\n","889/889 [==============================] - 0s 487us/step - loss: 84.8058 - val_loss: 96.4063\n","Epoch 534/1000\n","889/889 [==============================] - 0s 498us/step - loss: 87.9422 - val_loss: 97.6768\n","Epoch 535/1000\n","889/889 [==============================] - 0s 493us/step - loss: 88.2048 - val_loss: 92.8796\n","Epoch 536/1000\n","889/889 [==============================] - 0s 504us/step - loss: 87.3168 - val_loss: 102.6502\n","Epoch 537/1000\n","889/889 [==============================] - 0s 489us/step - loss: 95.6455 - val_loss: 89.3460\n","Epoch 538/1000\n","889/889 [==============================] - 0s 499us/step - loss: 91.3215 - val_loss: 90.3558\n","Epoch 539/1000\n","889/889 [==============================] - 0s 499us/step - loss: 93.3497 - val_loss: 91.3704\n","Epoch 540/1000\n","889/889 [==============================] - 0s 487us/step - loss: 90.3546 - val_loss: 92.1395\n","Epoch 541/1000\n","889/889 [==============================] - 0s 498us/step - loss: 92.4409 - val_loss: 87.4136\n","Epoch 542/1000\n","889/889 [==============================] - 0s 489us/step - loss: 93.4455 - val_loss: 96.2161\n","Epoch 543/1000\n","889/889 [==============================] - 0s 504us/step - loss: 91.0757 - val_loss: 98.3164\n","Epoch 544/1000\n","889/889 [==============================] - 0s 491us/step - loss: 91.6774 - val_loss: 95.9710\n","Epoch 545/1000\n","889/889 [==============================] - 0s 487us/step - loss: 91.4471 - val_loss: 95.3358\n","Epoch 546/1000\n","889/889 [==============================] - 0s 493us/step - loss: 90.2571 - val_loss: 94.4220\n","Epoch 547/1000\n","889/889 [==============================] - 0s 487us/step - loss: 90.2375 - val_loss: 94.3294\n","Epoch 548/1000\n","889/889 [==============================] - 0s 496us/step - loss: 90.4148 - val_loss: 93.3891\n","Epoch 549/1000\n","889/889 [==============================] - 0s 490us/step - loss: 90.3965 - val_loss: 92.4849\n","Epoch 550/1000\n","889/889 [==============================] - 0s 499us/step - loss: 89.3711 - val_loss: 92.1229\n","Epoch 551/1000\n","889/889 [==============================] - 0s 492us/step - loss: 89.3596 - val_loss: 90.5910\n","Epoch 552/1000\n","889/889 [==============================] - 0s 491us/step - loss: 91.0766 - val_loss: 88.7188\n","Epoch 553/1000\n","889/889 [==============================] - 0s 506us/step - loss: 90.5595 - val_loss: 87.3840\n","Epoch 554/1000\n","889/889 [==============================] - 0s 488us/step - loss: 89.4727 - val_loss: 88.2111\n","Epoch 555/1000\n","889/889 [==============================] - 0s 495us/step - loss: 88.6269 - val_loss: 88.7150\n","Epoch 556/1000\n","889/889 [==============================] - 0s 489us/step - loss: 88.7774 - val_loss: 89.7422\n","Epoch 557/1000\n","889/889 [==============================] - 0s 498us/step - loss: 87.6393 - val_loss: 91.1126\n","Epoch 558/1000\n","889/889 [==============================] - 0s 489us/step - loss: 86.8447 - val_loss: 90.7868\n","Epoch 559/1000\n","889/889 [==============================] - 0s 478us/step - loss: 86.9707 - val_loss: 91.2928\n","Epoch 560/1000\n","889/889 [==============================] - 0s 499us/step - loss: 88.1054 - val_loss: 92.3210\n","Epoch 561/1000\n","889/889 [==============================] - 0s 483us/step - loss: 86.7857 - val_loss: 91.8803\n","Epoch 562/1000\n","889/889 [==============================] - 0s 489us/step - loss: 87.4384 - val_loss: 92.1734\n","Epoch 563/1000\n","889/889 [==============================] - 0s 485us/step - loss: 86.3522 - val_loss: 93.2953\n","Epoch 564/1000\n","889/889 [==============================] - 0s 491us/step - loss: 86.1206 - val_loss: 93.7184\n","Epoch 565/1000\n","889/889 [==============================] - 0s 488us/step - loss: 85.2343 - val_loss: 90.5149\n","Epoch 566/1000\n","889/889 [==============================] - 0s 488us/step - loss: 85.4904 - val_loss: 89.9830\n","Epoch 567/1000\n","889/889 [==============================] - 0s 492us/step - loss: 85.0760 - val_loss: 91.7898\n","Epoch 568/1000\n","889/889 [==============================] - 0s 489us/step - loss: 86.9926 - val_loss: 88.8316\n","Epoch 569/1000\n","889/889 [==============================] - 0s 489us/step - loss: 83.8599 - val_loss: 90.2792\n","Epoch 570/1000\n","889/889 [==============================] - 0s 500us/step - loss: 85.9014 - val_loss: 90.4377\n","Epoch 571/1000\n","889/889 [==============================] - 0s 497us/step - loss: 84.9373 - val_loss: 88.8251\n","Epoch 572/1000\n","889/889 [==============================] - 0s 479us/step - loss: 85.0006 - val_loss: 91.0742\n","Epoch 573/1000\n","889/889 [==============================] - 0s 482us/step - loss: 83.3858 - val_loss: 92.7531\n","Epoch 574/1000\n","889/889 [==============================] - 0s 491us/step - loss: 86.3252 - val_loss: 91.4331\n","Epoch 575/1000\n","889/889 [==============================] - 0s 486us/step - loss: 83.5543 - val_loss: 93.4371\n","Epoch 576/1000\n","889/889 [==============================] - 0s 495us/step - loss: 83.5778 - val_loss: 95.0350\n","Epoch 577/1000\n","889/889 [==============================] - 0s 485us/step - loss: 82.6849 - val_loss: 92.0156\n","Epoch 578/1000\n","889/889 [==============================] - 0s 483us/step - loss: 82.2020 - val_loss: 91.5535\n","Epoch 579/1000\n","889/889 [==============================] - 0s 499us/step - loss: 82.6753 - val_loss: 92.6810\n","Epoch 580/1000\n","889/889 [==============================] - 0s 487us/step - loss: 83.0621 - val_loss: 93.1097\n","Epoch 581/1000\n","889/889 [==============================] - 0s 503us/step - loss: 82.6398 - val_loss: 91.8079\n","Epoch 582/1000\n","889/889 [==============================] - 0s 487us/step - loss: 82.1446 - val_loss: 92.0879\n","Epoch 583/1000\n","889/889 [==============================] - 0s 500us/step - loss: 82.0812 - val_loss: 93.5861\n","Epoch 584/1000\n","889/889 [==============================] - 0s 486us/step - loss: 82.0610 - val_loss: 92.2314\n","Epoch 585/1000\n","889/889 [==============================] - 0s 492us/step - loss: 82.0965 - val_loss: 92.7733\n","Epoch 586/1000\n","889/889 [==============================] - 0s 504us/step - loss: 82.3370 - val_loss: 92.4204\n","Epoch 587/1000\n","889/889 [==============================] - 0s 491us/step - loss: 81.9652 - val_loss: 92.6147\n","Epoch 588/1000\n","889/889 [==============================] - 0s 506us/step - loss: 81.9334 - val_loss: 90.3390\n","Epoch 589/1000\n","889/889 [==============================] - 0s 480us/step - loss: 82.5454 - val_loss: 92.1664\n","Epoch 590/1000\n","889/889 [==============================] - 0s 497us/step - loss: 81.9913 - val_loss: 93.1172\n","Epoch 591/1000\n","889/889 [==============================] - 0s 483us/step - loss: 83.9919 - val_loss: 91.6938\n","Epoch 592/1000\n","889/889 [==============================] - 0s 482us/step - loss: 83.1614 - val_loss: 91.7131\n","Epoch 593/1000\n","889/889 [==============================] - 0s 488us/step - loss: 82.1482 - val_loss: 92.9206\n","Epoch 594/1000\n","889/889 [==============================] - 0s 482us/step - loss: 83.2258 - val_loss: 91.5725\n","Epoch 595/1000\n","889/889 [==============================] - 0s 493us/step - loss: 83.1234 - val_loss: 90.2238\n","Epoch 596/1000\n","889/889 [==============================] - 0s 484us/step - loss: 81.9061 - val_loss: 93.1219\n","Epoch 597/1000\n","889/889 [==============================] - 0s 500us/step - loss: 82.1107 - val_loss: 97.3186\n","Epoch 598/1000\n","889/889 [==============================] - 0s 485us/step - loss: 82.7075 - val_loss: 92.8082\n","Epoch 599/1000\n","889/889 [==============================] - 0s 485us/step - loss: 81.6480 - val_loss: 92.9768\n","Epoch 600/1000\n","889/889 [==============================] - 0s 496us/step - loss: 82.8575 - val_loss: 92.7711\n","Epoch 601/1000\n","889/889 [==============================] - 0s 486us/step - loss: 83.2608 - val_loss: 88.9399\n","Epoch 602/1000\n","889/889 [==============================] - 0s 498us/step - loss: 83.2228 - val_loss: 90.2203\n","Epoch 603/1000\n","889/889 [==============================] - 0s 492us/step - loss: 82.9551 - val_loss: 90.9144\n","Epoch 604/1000\n","889/889 [==============================] - 0s 499us/step - loss: 82.9642 - val_loss: 93.6228\n","Epoch 605/1000\n","889/889 [==============================] - 0s 488us/step - loss: 81.7918 - val_loss: 93.2894\n","Epoch 606/1000\n","889/889 [==============================] - 0s 490us/step - loss: 83.2262 - val_loss: 90.6211\n","Epoch 607/1000\n","889/889 [==============================] - 0s 498us/step - loss: 81.9472 - val_loss: 90.2217\n","Epoch 608/1000\n","889/889 [==============================] - 0s 480us/step - loss: 81.9515 - val_loss: 91.0492\n","Epoch 609/1000\n","889/889 [==============================] - 0s 494us/step - loss: 81.5373 - val_loss: 92.1442\n","Epoch 610/1000\n","889/889 [==============================] - 0s 485us/step - loss: 82.6509 - val_loss: 93.4299\n","Epoch 611/1000\n","889/889 [==============================] - 0s 500us/step - loss: 82.9002 - val_loss: 92.1243\n","Epoch 612/1000\n","889/889 [==============================] - 0s 486us/step - loss: 83.4503 - val_loss: 93.4629\n","Epoch 613/1000\n","889/889 [==============================] - 0s 483us/step - loss: 82.9598 - val_loss: 92.2157\n","Epoch 614/1000\n","889/889 [==============================] - 0s 496us/step - loss: 85.4350 - val_loss: 90.4668\n","Epoch 615/1000\n","889/889 [==============================] - 0s 487us/step - loss: 83.7206 - val_loss: 90.0826\n","Epoch 616/1000\n","889/889 [==============================] - 0s 497us/step - loss: 82.9634 - val_loss: 92.5028\n","Epoch 617/1000\n","889/889 [==============================] - 0s 481us/step - loss: 82.1645 - val_loss: 92.5522\n","Epoch 618/1000\n","889/889 [==============================] - 0s 498us/step - loss: 81.3861 - val_loss: 91.9305\n","Epoch 619/1000\n","889/889 [==============================] - 0s 498us/step - loss: 83.0950 - val_loss: 91.9361\n","Epoch 620/1000\n","889/889 [==============================] - 0s 492us/step - loss: 81.9382 - val_loss: 93.1322\n","Epoch 621/1000\n","889/889 [==============================] - 0s 491us/step - loss: 82.2424 - val_loss: 93.8849\n","Epoch 622/1000\n","889/889 [==============================] - 0s 490us/step - loss: 82.1260 - val_loss: 91.0007\n","Epoch 623/1000\n","889/889 [==============================] - 0s 493us/step - loss: 82.3760 - val_loss: 92.0339\n","Epoch 624/1000\n","889/889 [==============================] - 0s 479us/step - loss: 80.7633 - val_loss: 92.7664\n","Epoch 625/1000\n","889/889 [==============================] - 0s 486us/step - loss: 81.5103 - val_loss: 91.9474\n","Epoch 626/1000\n","889/889 [==============================] - 0s 481us/step - loss: 80.7649 - val_loss: 92.3739\n","Epoch 627/1000\n","889/889 [==============================] - 0s 476us/step - loss: 81.2019 - val_loss: 93.3985\n","Epoch 628/1000\n","889/889 [==============================] - 0s 491us/step - loss: 81.1292 - val_loss: 95.0802\n","Epoch 629/1000\n","889/889 [==============================] - 0s 479us/step - loss: 81.6509 - val_loss: 91.5501\n","Epoch 630/1000\n","889/889 [==============================] - 0s 491us/step - loss: 80.5398 - val_loss: 92.2397\n","Epoch 631/1000\n","889/889 [==============================] - 0s 460us/step - loss: 80.4187 - val_loss: 94.5614\n","Epoch 632/1000\n","889/889 [==============================] - 0s 470us/step - loss: 80.9452 - val_loss: 90.2652\n","Epoch 633/1000\n","889/889 [==============================] - 0s 479us/step - loss: 80.7112 - val_loss: 91.4563\n","Epoch 634/1000\n","889/889 [==============================] - 0s 474us/step - loss: 81.4763 - val_loss: 92.2677\n","Epoch 635/1000\n","889/889 [==============================] - 0s 485us/step - loss: 80.9854 - val_loss: 90.0752\n","Epoch 636/1000\n","889/889 [==============================] - 0s 480us/step - loss: 81.8682 - val_loss: 90.7509\n","Epoch 637/1000\n","889/889 [==============================] - 0s 511us/step - loss: 81.2410 - val_loss: 94.2131\n","Epoch 638/1000\n","889/889 [==============================] - 0s 491us/step - loss: 84.2012 - val_loss: 93.7244\n","Epoch 639/1000\n","889/889 [==============================] - 0s 485us/step - loss: 81.5467 - val_loss: 90.5056\n","Epoch 640/1000\n","889/889 [==============================] - 0s 490us/step - loss: 82.4716 - val_loss: 90.0535\n","Epoch 641/1000\n","889/889 [==============================] - 0s 488us/step - loss: 80.6959 - val_loss: 91.3856\n","Epoch 642/1000\n","889/889 [==============================] - 0s 501us/step - loss: 81.5506 - val_loss: 91.8403\n","Epoch 643/1000\n","889/889 [==============================] - 0s 484us/step - loss: 83.4603 - val_loss: 91.0476\n","Epoch 644/1000\n","889/889 [==============================] - 0s 503us/step - loss: 81.9055 - val_loss: 93.5563\n","Epoch 645/1000\n","889/889 [==============================] - 0s 502us/step - loss: 80.1666 - val_loss: 93.2209\n","Epoch 646/1000\n","889/889 [==============================] - 0s 498us/step - loss: 81.9269 - val_loss: 94.7289\n","Epoch 647/1000\n","889/889 [==============================] - 0s 498us/step - loss: 83.9108 - val_loss: 93.4281\n","Epoch 648/1000\n","889/889 [==============================] - 0s 513us/step - loss: 80.9817 - val_loss: 89.7157\n","Epoch 649/1000\n","889/889 [==============================] - 0s 494us/step - loss: 81.2133 - val_loss: 91.7206\n","Epoch 650/1000\n","889/889 [==============================] - 0s 507us/step - loss: 81.2290 - val_loss: 93.8396\n","Epoch 651/1000\n","889/889 [==============================] - 0s 509us/step - loss: 80.8795 - val_loss: 91.3117\n","Epoch 652/1000\n","889/889 [==============================] - 0s 497us/step - loss: 80.3823 - val_loss: 92.8115\n","Epoch 653/1000\n","889/889 [==============================] - 0s 496us/step - loss: 79.6006 - val_loss: 95.9027\n","Epoch 654/1000\n","889/889 [==============================] - 0s 494us/step - loss: 79.8326 - val_loss: 92.6492\n","Epoch 655/1000\n","889/889 [==============================] - 0s 493us/step - loss: 79.3400 - val_loss: 90.9603\n","Epoch 656/1000\n","889/889 [==============================] - 0s 496us/step - loss: 79.4366 - val_loss: 92.3630\n","Epoch 657/1000\n","889/889 [==============================] - 0s 499us/step - loss: 78.9204 - val_loss: 93.1676\n","Epoch 658/1000\n","889/889 [==============================] - 0s 509us/step - loss: 79.0953 - val_loss: 92.4745\n","Epoch 659/1000\n","889/889 [==============================] - 0s 486us/step - loss: 79.4636 - val_loss: 92.0622\n","Epoch 660/1000\n","889/889 [==============================] - 0s 500us/step - loss: 79.5762 - val_loss: 92.3164\n","Epoch 661/1000\n","889/889 [==============================] - 0s 519us/step - loss: 79.6297 - val_loss: 91.4009\n","Epoch 662/1000\n","889/889 [==============================] - 0s 492us/step - loss: 81.1988 - val_loss: 94.0050\n","Epoch 663/1000\n","889/889 [==============================] - 0s 505us/step - loss: 80.5709 - val_loss: 92.9048\n","Epoch 664/1000\n","889/889 [==============================] - 0s 488us/step - loss: 79.2850 - val_loss: 91.5095\n","Epoch 665/1000\n","889/889 [==============================] - 0s 504us/step - loss: 78.6792 - val_loss: 92.4428\n","Epoch 666/1000\n","889/889 [==============================] - 0s 494us/step - loss: 78.9139 - val_loss: 91.5137\n","Epoch 667/1000\n","889/889 [==============================] - 0s 506us/step - loss: 79.1463 - val_loss: 90.8334\n","Epoch 668/1000\n","889/889 [==============================] - 0s 508us/step - loss: 79.4993 - val_loss: 90.6255\n","Epoch 669/1000\n","889/889 [==============================] - 0s 495us/step - loss: 79.3120 - val_loss: 92.3985\n","Epoch 670/1000\n","889/889 [==============================] - 0s 498us/step - loss: 80.1606 - val_loss: 93.2350\n","Epoch 671/1000\n","889/889 [==============================] - 0s 493us/step - loss: 80.5134 - val_loss: 91.6352\n","Epoch 672/1000\n","889/889 [==============================] - 0s 498us/step - loss: 82.4791 - val_loss: 91.6868\n","Epoch 673/1000\n","889/889 [==============================] - 0s 491us/step - loss: 80.8544 - val_loss: 93.0717\n","Epoch 674/1000\n","889/889 [==============================] - 0s 505us/step - loss: 78.8102 - val_loss: 93.4023\n","Epoch 675/1000\n","889/889 [==============================] - 0s 494us/step - loss: 79.6883 - val_loss: 91.6553\n","Epoch 676/1000\n","889/889 [==============================] - 0s 491us/step - loss: 79.6680 - val_loss: 91.6451\n","Epoch 677/1000\n","889/889 [==============================] - 0s 495us/step - loss: 79.2534 - val_loss: 93.6300\n","Epoch 678/1000\n","889/889 [==============================] - 0s 489us/step - loss: 79.4675 - val_loss: 90.5418\n","Epoch 679/1000\n","889/889 [==============================] - 0s 502us/step - loss: 80.1157 - val_loss: 91.0023\n","Epoch 680/1000\n","889/889 [==============================] - 0s 484us/step - loss: 78.8619 - val_loss: 93.9964\n","Epoch 681/1000\n","889/889 [==============================] - 0s 505us/step - loss: 78.9213 - val_loss: 93.0718\n","Epoch 682/1000\n","889/889 [==============================] - 0s 498us/step - loss: 78.6187 - val_loss: 92.0460\n","Epoch 683/1000\n","889/889 [==============================] - 0s 496us/step - loss: 78.4775 - val_loss: 95.7306\n","Epoch 684/1000\n","889/889 [==============================] - 0s 496us/step - loss: 78.8596 - val_loss: 92.3627\n","Epoch 685/1000\n","889/889 [==============================] - 0s 483us/step - loss: 78.9226 - val_loss: 91.7323\n","Epoch 686/1000\n","889/889 [==============================] - 0s 506us/step - loss: 79.8087 - val_loss: 91.7470\n","Epoch 687/1000\n","889/889 [==============================] - 0s 485us/step - loss: 78.8155 - val_loss: 92.8714\n","Epoch 688/1000\n","889/889 [==============================] - 0s 528us/step - loss: 78.9981 - val_loss: 91.0049\n","Epoch 689/1000\n","889/889 [==============================] - 0s 491us/step - loss: 79.9878 - val_loss: 91.3911\n","Epoch 690/1000\n","889/889 [==============================] - 0s 495us/step - loss: 80.3438 - val_loss: 95.0314\n","Epoch 691/1000\n","889/889 [==============================] - 0s 493us/step - loss: 78.7143 - val_loss: 92.7753\n","Epoch 692/1000\n","889/889 [==============================] - 0s 492us/step - loss: 78.5229 - val_loss: 93.5322\n","Epoch 693/1000\n","889/889 [==============================] - 0s 498us/step - loss: 78.9688 - val_loss: 93.9810\n","Epoch 694/1000\n","889/889 [==============================] - 0s 480us/step - loss: 80.0906 - val_loss: 94.3281\n","Epoch 695/1000\n","889/889 [==============================] - 0s 502us/step - loss: 78.5759 - val_loss: 94.1861\n","Epoch 696/1000\n","889/889 [==============================] - 0s 493us/step - loss: 78.0571 - val_loss: 90.3089\n","Epoch 697/1000\n","889/889 [==============================] - 0s 496us/step - loss: 78.1786 - val_loss: 91.8458\n","Epoch 698/1000\n","889/889 [==============================] - 0s 493us/step - loss: 77.8522 - val_loss: 91.7482\n","Epoch 699/1000\n","889/889 [==============================] - 0s 498us/step - loss: 78.0890 - val_loss: 88.8056\n","Epoch 700/1000\n","889/889 [==============================] - 0s 492us/step - loss: 80.0160 - val_loss: 92.8746\n","Epoch 701/1000\n","889/889 [==============================] - 0s 477us/step - loss: 77.6097 - val_loss: 95.5838\n","Epoch 702/1000\n","889/889 [==============================] - 0s 504us/step - loss: 78.6011 - val_loss: 94.5293\n","Epoch 703/1000\n","889/889 [==============================] - 0s 486us/step - loss: 77.6078 - val_loss: 92.6990\n","Epoch 704/1000\n","889/889 [==============================] - 0s 490us/step - loss: 77.7050 - val_loss: 99.1541\n","Epoch 705/1000\n","889/889 [==============================] - 0s 510us/step - loss: 81.2823 - val_loss: 91.2406\n","Epoch 706/1000\n","889/889 [==============================] - 0s 496us/step - loss: 79.9412 - val_loss: 93.6091\n","Epoch 707/1000\n","889/889 [==============================] - 0s 502us/step - loss: 79.7381 - val_loss: 94.6103\n","Epoch 708/1000\n","889/889 [==============================] - 0s 485us/step - loss: 80.6989 - val_loss: 89.7831\n","Epoch 709/1000\n","889/889 [==============================] - 0s 512us/step - loss: 80.3854 - val_loss: 91.5574\n","Epoch 710/1000\n","889/889 [==============================] - 0s 487us/step - loss: 79.8521 - val_loss: 96.7281\n","Epoch 711/1000\n","889/889 [==============================] - 0s 491us/step - loss: 80.0753 - val_loss: 93.1530\n","Epoch 712/1000\n","889/889 [==============================] - 0s 490us/step - loss: 77.0550 - val_loss: 90.1428\n","Epoch 713/1000\n","889/889 [==============================] - 0s 480us/step - loss: 78.5986 - val_loss: 93.8638\n","Epoch 714/1000\n","889/889 [==============================] - 0s 479us/step - loss: 77.6696 - val_loss: 95.5432\n","Epoch 715/1000\n","889/889 [==============================] - 0s 461us/step - loss: 79.3517 - val_loss: 92.4557\n","Epoch 716/1000\n","889/889 [==============================] - 0s 494us/step - loss: 76.0038 - val_loss: 92.8262\n","Epoch 717/1000\n","889/889 [==============================] - 0s 488us/step - loss: 78.5628 - val_loss: 92.8245\n","Epoch 718/1000\n","889/889 [==============================] - 0s 492us/step - loss: 76.7869 - val_loss: 91.5063\n","Epoch 719/1000\n","889/889 [==============================] - 0s 496us/step - loss: 75.8471 - val_loss: 93.8603\n","Epoch 720/1000\n","889/889 [==============================] - 0s 496us/step - loss: 79.1611 - val_loss: 92.4922\n","Epoch 721/1000\n","889/889 [==============================] - 0s 496us/step - loss: 81.5697 - val_loss: 91.4585\n","Epoch 722/1000\n","889/889 [==============================] - 0s 489us/step - loss: 84.5726 - val_loss: 90.5892\n","Epoch 723/1000\n","889/889 [==============================] - 0s 496us/step - loss: 84.3213 - val_loss: 92.0335\n","Epoch 724/1000\n","889/889 [==============================] - 0s 482us/step - loss: 84.0994 - val_loss: 90.0496\n","Epoch 725/1000\n","889/889 [==============================] - 0s 486us/step - loss: 84.1736 - val_loss: 90.6843\n","Epoch 726/1000\n","889/889 [==============================] - 0s 487us/step - loss: 84.0349 - val_loss: 94.1576\n","Epoch 727/1000\n","889/889 [==============================] - 0s 490us/step - loss: 88.3400 - val_loss: 91.1217\n","Epoch 728/1000\n","889/889 [==============================] - 0s 501us/step - loss: 82.9742 - val_loss: 88.5547\n","Epoch 729/1000\n","889/889 [==============================] - 0s 495us/step - loss: 85.0110 - val_loss: 91.5611\n","Epoch 730/1000\n","889/889 [==============================] - 0s 505us/step - loss: 83.0733 - val_loss: 92.1450\n","Epoch 731/1000\n","889/889 [==============================] - 0s 489us/step - loss: 83.0415 - val_loss: 91.7353\n","Epoch 732/1000\n","889/889 [==============================] - 0s 492us/step - loss: 81.1368 - val_loss: 93.3649\n","Epoch 733/1000\n","889/889 [==============================] - 0s 490us/step - loss: 82.5522 - val_loss: 94.7507\n","Epoch 734/1000\n","889/889 [==============================] - 0s 489us/step - loss: 82.4166 - val_loss: 90.5406\n","Epoch 735/1000\n","889/889 [==============================] - 0s 499us/step - loss: 81.6672 - val_loss: 91.9226\n","Epoch 736/1000\n","889/889 [==============================] - 0s 491us/step - loss: 80.7894 - val_loss: 93.5530\n","Epoch 737/1000\n","889/889 [==============================] - 0s 504us/step - loss: 81.2600 - val_loss: 91.0074\n","Epoch 738/1000\n","889/889 [==============================] - 0s 491us/step - loss: 82.0189 - val_loss: 92.5006\n","Epoch 739/1000\n","889/889 [==============================] - 0s 494us/step - loss: 82.5271 - val_loss: 93.2882\n","Epoch 740/1000\n","889/889 [==============================] - 0s 488us/step - loss: 80.1219 - val_loss: 89.0507\n","Epoch 741/1000\n","889/889 [==============================] - 0s 492us/step - loss: 82.0483 - val_loss: 90.5335\n","Epoch 742/1000\n","889/889 [==============================] - 0s 499us/step - loss: 82.0770 - val_loss: 92.9356\n","Epoch 743/1000\n","889/889 [==============================] - 0s 496us/step - loss: 80.6865 - val_loss: 95.2621\n","Epoch 744/1000\n","889/889 [==============================] - 0s 503us/step - loss: 82.5922 - val_loss: 95.1323\n","Epoch 745/1000\n","889/889 [==============================] - 0s 491us/step - loss: 78.9733 - val_loss: 93.8566\n","Epoch 746/1000\n","889/889 [==============================] - 0s 489us/step - loss: 80.1629 - val_loss: 90.3429\n","Epoch 747/1000\n","889/889 [==============================] - 0s 493us/step - loss: 81.4927 - val_loss: 91.2033\n","Epoch 748/1000\n","889/889 [==============================] - 0s 482us/step - loss: 78.7925 - val_loss: 92.8177\n","Epoch 749/1000\n","889/889 [==============================] - 0s 510us/step - loss: 79.5273 - val_loss: 90.6129\n","Epoch 750/1000\n","889/889 [==============================] - 0s 489us/step - loss: 80.1789 - val_loss: 91.2063\n","Epoch 751/1000\n","889/889 [==============================] - 0s 499us/step - loss: 77.0577 - val_loss: 93.4476\n","Epoch 752/1000\n","889/889 [==============================] - 0s 490us/step - loss: 77.4733 - val_loss: 92.2269\n","Epoch 753/1000\n","889/889 [==============================] - 0s 491us/step - loss: 76.8627 - val_loss: 91.7419\n","Epoch 754/1000\n","889/889 [==============================] - 0s 498us/step - loss: 78.0805 - val_loss: 94.6020\n","Epoch 755/1000\n","889/889 [==============================] - 0s 492us/step - loss: 77.3323 - val_loss: 94.2309\n","Epoch 756/1000\n","889/889 [==============================] - 0s 518us/step - loss: 76.6895 - val_loss: 91.3675\n","Epoch 757/1000\n","889/889 [==============================] - 0s 492us/step - loss: 77.2153 - val_loss: 90.4851\n","Epoch 758/1000\n","889/889 [==============================] - 0s 505us/step - loss: 77.3915 - val_loss: 92.5955\n","Epoch 759/1000\n","889/889 [==============================] - 0s 491us/step - loss: 76.0675 - val_loss: 93.6699\n","Epoch 760/1000\n","889/889 [==============================] - 0s 494us/step - loss: 77.3505 - val_loss: 93.8572\n","Epoch 761/1000\n","889/889 [==============================] - 0s 511us/step - loss: 75.7498 - val_loss: 91.4571\n","Epoch 762/1000\n","889/889 [==============================] - 0s 494us/step - loss: 76.2658 - val_loss: 91.8118\n","Epoch 763/1000\n","889/889 [==============================] - 0s 506us/step - loss: 75.4347 - val_loss: 90.0259\n","Epoch 764/1000\n","889/889 [==============================] - 0s 489us/step - loss: 75.9290 - val_loss: 90.6449\n","Epoch 765/1000\n","889/889 [==============================] - 0s 512us/step - loss: 75.5898 - val_loss: 94.3381\n","Epoch 766/1000\n","889/889 [==============================] - 0s 487us/step - loss: 75.9119 - val_loss: 95.9451\n","Epoch 767/1000\n","889/889 [==============================] - 0s 469us/step - loss: 78.2110 - val_loss: 90.3961\n","Epoch 768/1000\n","889/889 [==============================] - 0s 478us/step - loss: 77.8633 - val_loss: 91.5558\n","Epoch 769/1000\n","889/889 [==============================] - 0s 467us/step - loss: 75.5779 - val_loss: 95.1307\n","Epoch 770/1000\n","889/889 [==============================] - 0s 514us/step - loss: 74.8909 - val_loss: 94.2834\n","Epoch 771/1000\n","889/889 [==============================] - 0s 503us/step - loss: 76.5226 - val_loss: 92.8579\n","Epoch 772/1000\n","889/889 [==============================] - 0s 532us/step - loss: 77.0339 - val_loss: 94.1827\n","Epoch 773/1000\n","889/889 [==============================] - 0s 503us/step - loss: 76.4708 - val_loss: 94.7935\n","Epoch 774/1000\n","889/889 [==============================] - 0s 499us/step - loss: 75.7489 - val_loss: 93.0495\n","Epoch 775/1000\n","889/889 [==============================] - 0s 515us/step - loss: 77.8314 - val_loss: 91.6955\n","Epoch 776/1000\n","889/889 [==============================] - 0s 508us/step - loss: 76.5714 - val_loss: 91.1880\n","Epoch 777/1000\n","889/889 [==============================] - 0s 511us/step - loss: 76.5594 - val_loss: 96.7583\n","Epoch 778/1000\n","889/889 [==============================] - 0s 499us/step - loss: 75.6054 - val_loss: 94.4726\n","Epoch 779/1000\n","889/889 [==============================] - 0s 513us/step - loss: 76.7347 - val_loss: 93.4168\n","Epoch 780/1000\n","889/889 [==============================] - 0s 508us/step - loss: 75.9109 - val_loss: 95.0919\n","Epoch 781/1000\n","889/889 [==============================] - 0s 516us/step - loss: 75.1761 - val_loss: 95.7821\n","Epoch 782/1000\n","889/889 [==============================] - 0s 514us/step - loss: 75.2133 - val_loss: 91.0046\n","Epoch 783/1000\n","889/889 [==============================] - 0s 496us/step - loss: 76.1070 - val_loss: 93.6511\n","Epoch 784/1000\n","889/889 [==============================] - 0s 510us/step - loss: 74.9410 - val_loss: 96.3241\n","Epoch 785/1000\n","889/889 [==============================] - 0s 492us/step - loss: 74.2348 - val_loss: 93.2045\n","Epoch 786/1000\n","889/889 [==============================] - 0s 497us/step - loss: 75.6133 - val_loss: 93.0068\n","Epoch 787/1000\n","889/889 [==============================] - 0s 508us/step - loss: 75.8030 - val_loss: 89.3032\n","Epoch 788/1000\n","889/889 [==============================] - 0s 504us/step - loss: 77.3963 - val_loss: 89.5290\n","Epoch 789/1000\n","889/889 [==============================] - 0s 485us/step - loss: 76.0855 - val_loss: 92.3589\n","Epoch 790/1000\n","889/889 [==============================] - 0s 498us/step - loss: 76.2943 - val_loss: 94.9202\n","Epoch 791/1000\n","889/889 [==============================] - 0s 502us/step - loss: 75.3489 - val_loss: 93.8534\n","Epoch 792/1000\n","889/889 [==============================] - 0s 499us/step - loss: 75.6751 - val_loss: 92.5494\n","Epoch 793/1000\n","889/889 [==============================] - 0s 507us/step - loss: 76.2655 - val_loss: 93.5032\n","Epoch 794/1000\n","889/889 [==============================] - 0s 494us/step - loss: 75.3563 - val_loss: 91.3470\n","Epoch 795/1000\n","889/889 [==============================] - 0s 522us/step - loss: 75.9774 - val_loss: 94.1246\n","Epoch 796/1000\n","889/889 [==============================] - 0s 497us/step - loss: 74.5370 - val_loss: 95.6159\n","Epoch 797/1000\n","889/889 [==============================] - 0s 519us/step - loss: 74.6717 - val_loss: 92.9638\n","Epoch 798/1000\n","889/889 [==============================] - 0s 500us/step - loss: 74.5348 - val_loss: 94.4656\n","Epoch 799/1000\n","889/889 [==============================] - 0s 491us/step - loss: 76.0279 - val_loss: 94.8314\n","Epoch 800/1000\n","889/889 [==============================] - 0s 500us/step - loss: 74.1533 - val_loss: 95.0676\n","Epoch 801/1000\n","889/889 [==============================] - 0s 497us/step - loss: 74.2572 - val_loss: 96.4987\n","Epoch 802/1000\n","889/889 [==============================] - 0s 495us/step - loss: 75.1361 - val_loss: 95.6553\n","Epoch 803/1000\n","889/889 [==============================] - 0s 487us/step - loss: 74.0646 - val_loss: 91.7811\n","Epoch 804/1000\n","889/889 [==============================] - 0s 496us/step - loss: 75.1515 - val_loss: 93.9690\n","Epoch 805/1000\n","889/889 [==============================] - 0s 498us/step - loss: 75.9843 - val_loss: 93.9289\n","Epoch 806/1000\n","889/889 [==============================] - 0s 486us/step - loss: 74.6013 - val_loss: 91.3931\n","Epoch 807/1000\n","889/889 [==============================] - 0s 495us/step - loss: 76.0405 - val_loss: 91.0470\n","Epoch 808/1000\n","889/889 [==============================] - 0s 492us/step - loss: 75.2518 - val_loss: 96.6908\n","Epoch 809/1000\n","889/889 [==============================] - 0s 499us/step - loss: 74.5501 - val_loss: 96.1194\n","Epoch 810/1000\n","889/889 [==============================] - 0s 492us/step - loss: 75.8246 - val_loss: 92.1066\n","Epoch 811/1000\n","889/889 [==============================] - 0s 493us/step - loss: 73.5571 - val_loss: 97.6096\n","Epoch 812/1000\n","889/889 [==============================] - 0s 482us/step - loss: 74.4105 - val_loss: 96.1714\n","Epoch 813/1000\n","889/889 [==============================] - 0s 479us/step - loss: 73.2377 - val_loss: 92.3482\n","Epoch 814/1000\n","889/889 [==============================] - 0s 476us/step - loss: 76.1036 - val_loss: 92.5769\n","Epoch 815/1000\n","889/889 [==============================] - 0s 476us/step - loss: 73.9895 - val_loss: 96.9986\n","Epoch 816/1000\n","889/889 [==============================] - 0s 487us/step - loss: 75.1093 - val_loss: 95.7344\n","Epoch 817/1000\n","889/889 [==============================] - 0s 485us/step - loss: 75.8467 - val_loss: 91.6949\n","Epoch 818/1000\n","889/889 [==============================] - 0s 484us/step - loss: 76.2651 - val_loss: 90.7258\n","Epoch 819/1000\n","889/889 [==============================] - 0s 492us/step - loss: 75.8561 - val_loss: 94.5755\n","Epoch 820/1000\n","889/889 [==============================] - 0s 490us/step - loss: 75.9184 - val_loss: 89.1013\n","Epoch 821/1000\n","889/889 [==============================] - 0s 502us/step - loss: 79.4462 - val_loss: 90.0180\n","Epoch 822/1000\n","889/889 [==============================] - 0s 492us/step - loss: 75.2807 - val_loss: 95.4922\n","Epoch 823/1000\n","889/889 [==============================] - 0s 494us/step - loss: 78.6811 - val_loss: 96.9224\n","Epoch 824/1000\n","889/889 [==============================] - 0s 497us/step - loss: 74.3742 - val_loss: 93.2643\n","Epoch 825/1000\n","889/889 [==============================] - 0s 472us/step - loss: 74.5528 - val_loss: 96.4046\n","Epoch 826/1000\n","889/889 [==============================] - 0s 499us/step - loss: 76.6750 - val_loss: 95.2557\n","Epoch 827/1000\n","889/889 [==============================] - 0s 491us/step - loss: 73.5928 - val_loss: 92.1135\n","Epoch 828/1000\n","889/889 [==============================] - 0s 486us/step - loss: 73.9341 - val_loss: 94.0955\n","Epoch 829/1000\n","889/889 [==============================] - 0s 493us/step - loss: 74.2341 - val_loss: 95.1744\n","Epoch 830/1000\n","889/889 [==============================] - 0s 504us/step - loss: 74.7933 - val_loss: 90.7485\n","Epoch 831/1000\n","889/889 [==============================] - 0s 490us/step - loss: 74.9914 - val_loss: 92.7005\n","Epoch 832/1000\n","889/889 [==============================] - 0s 488us/step - loss: 75.2186 - val_loss: 94.2988\n","Epoch 833/1000\n","889/889 [==============================] - 0s 501us/step - loss: 74.6099 - val_loss: 93.1820\n","Epoch 834/1000\n","889/889 [==============================] - 0s 490us/step - loss: 75.9926 - val_loss: 91.9849\n","Epoch 835/1000\n","889/889 [==============================] - 0s 475us/step - loss: 74.8513 - val_loss: 93.8187\n","Epoch 836/1000\n","889/889 [==============================] - 0s 463us/step - loss: 73.7480 - val_loss: 92.8383\n","Epoch 837/1000\n","889/889 [==============================] - 0s 478us/step - loss: 73.4895 - val_loss: 91.9375\n","Epoch 838/1000\n","889/889 [==============================] - 0s 460us/step - loss: 74.0621 - val_loss: 92.2163\n","Epoch 839/1000\n","889/889 [==============================] - 0s 467us/step - loss: 74.7173 - val_loss: 93.8307\n","Epoch 840/1000\n","889/889 [==============================] - 0s 472us/step - loss: 74.3263 - val_loss: 93.3654\n","Epoch 841/1000\n","889/889 [==============================] - 0s 466us/step - loss: 75.3428 - val_loss: 94.3855\n","Epoch 842/1000\n","889/889 [==============================] - 0s 483us/step - loss: 73.9550 - val_loss: 94.0529\n","Epoch 843/1000\n","889/889 [==============================] - 0s 469us/step - loss: 73.2324 - val_loss: 93.1879\n","Epoch 844/1000\n","889/889 [==============================] - 0s 473us/step - loss: 74.1811 - val_loss: 95.7354\n","Epoch 845/1000\n","889/889 [==============================] - 0s 480us/step - loss: 73.3043 - val_loss: 94.5377\n","Epoch 846/1000\n","889/889 [==============================] - 0s 459us/step - loss: 74.0671 - val_loss: 94.1693\n","Epoch 847/1000\n","889/889 [==============================] - 0s 483us/step - loss: 73.6093 - val_loss: 92.9554\n","Epoch 848/1000\n","889/889 [==============================] - 0s 463us/step - loss: 74.9864 - val_loss: 91.0932\n","Epoch 849/1000\n","889/889 [==============================] - 0s 478us/step - loss: 75.9341 - val_loss: 93.7627\n","Epoch 850/1000\n","889/889 [==============================] - 0s 477us/step - loss: 75.3016 - val_loss: 93.8159\n","Epoch 851/1000\n","889/889 [==============================] - 0s 471us/step - loss: 74.9910 - val_loss: 95.6386\n","Epoch 852/1000\n","889/889 [==============================] - 0s 476us/step - loss: 74.2923 - val_loss: 96.1877\n","Epoch 853/1000\n","889/889 [==============================] - 0s 472us/step - loss: 73.9875 - val_loss: 94.2950\n","Epoch 854/1000\n","889/889 [==============================] - 0s 477us/step - loss: 73.3027 - val_loss: 93.7261\n","Epoch 855/1000\n","889/889 [==============================] - 0s 458us/step - loss: 73.4438 - val_loss: 93.7662\n","Epoch 856/1000\n","889/889 [==============================] - 0s 471us/step - loss: 72.8253 - val_loss: 95.4975\n","Epoch 857/1000\n","889/889 [==============================] - 0s 479us/step - loss: 73.1598 - val_loss: 91.6701\n","Epoch 858/1000\n","889/889 [==============================] - 0s 464us/step - loss: 73.8132 - val_loss: 92.3788\n","Epoch 859/1000\n","889/889 [==============================] - 0s 475us/step - loss: 72.8641 - val_loss: 94.4119\n","Epoch 860/1000\n","889/889 [==============================] - 0s 469us/step - loss: 72.7038 - val_loss: 96.1426\n","Epoch 861/1000\n","889/889 [==============================] - 0s 468us/step - loss: 72.7099 - val_loss: 94.3421\n","Epoch 862/1000\n","889/889 [==============================] - 0s 485us/step - loss: 72.1913 - val_loss: 95.2963\n","Epoch 863/1000\n","889/889 [==============================] - 0s 460us/step - loss: 73.0477 - val_loss: 93.5118\n","Epoch 864/1000\n","889/889 [==============================] - 0s 488us/step - loss: 74.6182 - val_loss: 95.7858\n","Epoch 865/1000\n","889/889 [==============================] - 0s 466us/step - loss: 73.8187 - val_loss: 99.0105\n","Epoch 866/1000\n","889/889 [==============================] - 0s 479us/step - loss: 73.9484 - val_loss: 96.7795\n","Epoch 867/1000\n","889/889 [==============================] - 0s 478us/step - loss: 72.9625 - val_loss: 93.9275\n","Epoch 868/1000\n","889/889 [==============================] - 0s 467us/step - loss: 72.4312 - val_loss: 94.6633\n","Epoch 869/1000\n","889/889 [==============================] - 0s 476us/step - loss: 72.8283 - val_loss: 93.3164\n","Epoch 870/1000\n","889/889 [==============================] - 0s 472us/step - loss: 75.3569 - val_loss: 93.5132\n","Epoch 871/1000\n","889/889 [==============================] - 0s 490us/step - loss: 77.6499 - val_loss: 91.9195\n","Epoch 872/1000\n","889/889 [==============================] - 0s 473us/step - loss: 78.4621 - val_loss: 90.5948\n","Epoch 873/1000\n","889/889 [==============================] - 0s 477us/step - loss: 76.8702 - val_loss: 92.7063\n","Epoch 874/1000\n","889/889 [==============================] - 0s 476us/step - loss: 76.0763 - val_loss: 92.0865\n","Epoch 875/1000\n","889/889 [==============================] - 0s 471us/step - loss: 75.9839 - val_loss: 93.4268\n","Epoch 876/1000\n","889/889 [==============================] - 0s 495us/step - loss: 74.9617 - val_loss: 92.2682\n","Epoch 877/1000\n","889/889 [==============================] - 0s 472us/step - loss: 74.8054 - val_loss: 93.1011\n","Epoch 878/1000\n","889/889 [==============================] - 0s 471us/step - loss: 76.4418 - val_loss: 92.7465\n","Epoch 879/1000\n","889/889 [==============================] - 0s 479us/step - loss: 75.7707 - val_loss: 91.5424\n","Epoch 880/1000\n","889/889 [==============================] - 0s 468us/step - loss: 75.7772 - val_loss: 95.3254\n","Epoch 881/1000\n","889/889 [==============================] - 0s 479us/step - loss: 76.4516 - val_loss: 98.4629\n","Epoch 882/1000\n","889/889 [==============================] - 0s 473us/step - loss: 74.9617 - val_loss: 90.9911\n","Epoch 883/1000\n","889/889 [==============================] - 0s 507us/step - loss: 79.1541 - val_loss: 97.3593\n","Epoch 884/1000\n","889/889 [==============================] - 0s 499us/step - loss: 77.9513 - val_loss: 95.5535\n","Epoch 885/1000\n","889/889 [==============================] - 0s 488us/step - loss: 75.1281 - val_loss: 91.2486\n","Epoch 886/1000\n","889/889 [==============================] - 0s 507us/step - loss: 76.6097 - val_loss: 90.6526\n","Epoch 887/1000\n","889/889 [==============================] - 0s 506us/step - loss: 73.5505 - val_loss: 95.0715\n","Epoch 888/1000\n","889/889 [==============================] - 0s 509us/step - loss: 75.4966 - val_loss: 93.9495\n","Epoch 889/1000\n","889/889 [==============================] - 0s 491us/step - loss: 73.2141 - val_loss: 91.3986\n","Epoch 890/1000\n","889/889 [==============================] - 0s 492us/step - loss: 75.7519 - val_loss: 91.1563\n","Epoch 891/1000\n","889/889 [==============================] - 0s 487us/step - loss: 74.7299 - val_loss: 93.0639\n","Epoch 892/1000\n","889/889 [==============================] - 0s 486us/step - loss: 73.3662 - val_loss: 92.5525\n","Epoch 893/1000\n","889/889 [==============================] - 0s 515us/step - loss: 74.8313 - val_loss: 92.1666\n","Epoch 894/1000\n","889/889 [==============================] - 0s 503us/step - loss: 73.5877 - val_loss: 95.1773\n","Epoch 895/1000\n","889/889 [==============================] - 0s 507us/step - loss: 74.2468 - val_loss: 95.8533\n","Epoch 896/1000\n","889/889 [==============================] - 0s 499us/step - loss: 72.5516 - val_loss: 95.7666\n","Epoch 897/1000\n","889/889 [==============================] - 0s 508us/step - loss: 74.1435 - val_loss: 95.8185\n","Epoch 898/1000\n","889/889 [==============================] - 0s 501us/step - loss: 72.6201 - val_loss: 93.2587\n","Epoch 899/1000\n","889/889 [==============================] - 0s 492us/step - loss: 72.9759 - val_loss: 92.3683\n","Epoch 900/1000\n","889/889 [==============================] - 0s 499us/step - loss: 72.0338 - val_loss: 96.0729\n","Epoch 901/1000\n","889/889 [==============================] - 0s 499us/step - loss: 72.9440 - val_loss: 96.3279\n","Epoch 902/1000\n","889/889 [==============================] - 0s 511us/step - loss: 71.7235 - val_loss: 94.2308\n","Epoch 903/1000\n","889/889 [==============================] - 0s 510us/step - loss: 73.1256 - val_loss: 93.1311\n","Epoch 904/1000\n","889/889 [==============================] - 0s 505us/step - loss: 73.4799 - val_loss: 96.4644\n","Epoch 905/1000\n","889/889 [==============================] - 0s 498us/step - loss: 74.6589 - val_loss: 97.2806\n","Epoch 906/1000\n","889/889 [==============================] - 0s 508us/step - loss: 74.9259 - val_loss: 93.6575\n","Epoch 907/1000\n","889/889 [==============================] - 0s 496us/step - loss: 74.6025 - val_loss: 92.9847\n","Epoch 908/1000\n","889/889 [==============================] - 0s 494us/step - loss: 75.6895 - val_loss: 93.8400\n","Epoch 909/1000\n","889/889 [==============================] - 0s 506us/step - loss: 73.6710 - val_loss: 97.0279\n","Epoch 910/1000\n","889/889 [==============================] - 0s 492us/step - loss: 73.6429 - val_loss: 96.6423\n","Epoch 911/1000\n","889/889 [==============================] - 0s 501us/step - loss: 74.3566 - val_loss: 95.3107\n","Epoch 912/1000\n","889/889 [==============================] - 0s 501us/step - loss: 72.9013 - val_loss: 94.6144\n","Epoch 913/1000\n","889/889 [==============================] - 0s 516us/step - loss: 75.3219 - val_loss: 92.9248\n","Epoch 914/1000\n","889/889 [==============================] - 0s 498us/step - loss: 73.4912 - val_loss: 91.8238\n","Epoch 915/1000\n","889/889 [==============================] - 0s 489us/step - loss: 73.6525 - val_loss: 94.4470\n","Epoch 916/1000\n","889/889 [==============================] - 0s 505us/step - loss: 73.0582 - val_loss: 95.9865\n","Epoch 917/1000\n","889/889 [==============================] - 0s 486us/step - loss: 72.9971 - val_loss: 91.9607\n","Epoch 918/1000\n","889/889 [==============================] - 0s 501us/step - loss: 72.9473 - val_loss: 91.4785\n","Epoch 919/1000\n","889/889 [==============================] - 0s 490us/step - loss: 73.0624 - val_loss: 96.4961\n","Epoch 920/1000\n","889/889 [==============================] - 0s 507us/step - loss: 72.2951 - val_loss: 94.5468\n","Epoch 921/1000\n","889/889 [==============================] - 0s 514us/step - loss: 73.0853 - val_loss: 94.8640\n","Epoch 922/1000\n","889/889 [==============================] - 0s 498us/step - loss: 72.7813 - val_loss: 95.9583\n","Epoch 923/1000\n","889/889 [==============================] - 0s 511us/step - loss: 74.1603 - val_loss: 95.4949\n","Epoch 924/1000\n","889/889 [==============================] - 0s 498us/step - loss: 72.2347 - val_loss: 93.6966\n","Epoch 925/1000\n","889/889 [==============================] - 0s 500us/step - loss: 72.6826 - val_loss: 95.3885\n","Epoch 926/1000\n","889/889 [==============================] - 0s 491us/step - loss: 73.3327 - val_loss: 95.1726\n","Epoch 927/1000\n","889/889 [==============================] - 0s 493us/step - loss: 72.1695 - val_loss: 91.2433\n","Epoch 928/1000\n","889/889 [==============================] - 0s 486us/step - loss: 73.6946 - val_loss: 90.1519\n","Epoch 929/1000\n","889/889 [==============================] - 0s 497us/step - loss: 73.6620 - val_loss: 93.5338\n","Epoch 930/1000\n","889/889 [==============================] - 0s 484us/step - loss: 71.3676 - val_loss: 95.8436\n","Epoch 931/1000\n","889/889 [==============================] - 0s 479us/step - loss: 72.0686 - val_loss: 93.6803\n","Epoch 932/1000\n","889/889 [==============================] - 0s 472us/step - loss: 73.2779 - val_loss: 92.8340\n","Epoch 933/1000\n","889/889 [==============================] - 0s 470us/step - loss: 72.5428 - val_loss: 94.5448\n","Epoch 934/1000\n","889/889 [==============================] - 0s 480us/step - loss: 73.5294 - val_loss: 94.5256\n","Epoch 935/1000\n","889/889 [==============================] - 0s 480us/step - loss: 72.5606 - val_loss: 92.4795\n","Epoch 936/1000\n","889/889 [==============================] - 0s 464us/step - loss: 90.6757 - val_loss: 81.8766\n","Epoch 937/1000\n","889/889 [==============================] - 0s 474us/step - loss: 80.1811 - val_loss: 94.2804\n","Epoch 938/1000\n","889/889 [==============================] - 0s 466us/step - loss: 81.9859 - val_loss: 96.8805\n","Epoch 939/1000\n","889/889 [==============================] - 0s 479us/step - loss: 88.2511 - val_loss: 91.0566\n","Epoch 940/1000\n","889/889 [==============================] - 0s 463us/step - loss: 84.5071 - val_loss: 87.1297\n","Epoch 941/1000\n","889/889 [==============================] - 0s 481us/step - loss: 83.2318 - val_loss: 87.9345\n","Epoch 942/1000\n","889/889 [==============================] - 0s 478us/step - loss: 82.2923 - val_loss: 90.1191\n","Epoch 943/1000\n","889/889 [==============================] - 0s 464us/step - loss: 81.2629 - val_loss: 91.0295\n","Epoch 944/1000\n","889/889 [==============================] - 0s 482us/step - loss: 82.1607 - val_loss: 90.2446\n","Epoch 945/1000\n","889/889 [==============================] - 0s 468us/step - loss: 81.8287 - val_loss: 90.9396\n","Epoch 946/1000\n","889/889 [==============================] - 0s 480us/step - loss: 81.5731 - val_loss: 89.3485\n","Epoch 947/1000\n","889/889 [==============================] - 0s 474us/step - loss: 81.4210 - val_loss: 92.2237\n","Epoch 948/1000\n","889/889 [==============================] - 0s 499us/step - loss: 80.0382 - val_loss: 94.2472\n","Epoch 949/1000\n","889/889 [==============================] - 0s 500us/step - loss: 79.4431 - val_loss: 92.0867\n","Epoch 950/1000\n","889/889 [==============================] - 0s 501us/step - loss: 78.9381 - val_loss: 92.0390\n","Epoch 951/1000\n","889/889 [==============================] - 0s 505us/step - loss: 79.5623 - val_loss: 93.1228\n","Epoch 952/1000\n","889/889 [==============================] - 0s 498us/step - loss: 78.5296 - val_loss: 92.6179\n","Epoch 953/1000\n","889/889 [==============================] - 0s 515us/step - loss: 79.8907 - val_loss: 94.6540\n","Epoch 954/1000\n","889/889 [==============================] - 0s 492us/step - loss: 78.1097 - val_loss: 94.4092\n","Epoch 955/1000\n","889/889 [==============================] - 0s 491us/step - loss: 78.3166 - val_loss: 93.0585\n","Epoch 956/1000\n","889/889 [==============================] - 0s 496us/step - loss: 78.2728 - val_loss: 94.4572\n","Epoch 957/1000\n","889/889 [==============================] - 0s 499us/step - loss: 79.8196 - val_loss: 90.6062\n","Epoch 958/1000\n","889/889 [==============================] - 0s 501us/step - loss: 79.1652 - val_loss: 90.7855\n","Epoch 959/1000\n","889/889 [==============================] - 0s 492us/step - loss: 79.7412 - val_loss: 92.3769\n","Epoch 960/1000\n","889/889 [==============================] - 0s 515us/step - loss: 78.1723 - val_loss: 95.0820\n","Epoch 961/1000\n","889/889 [==============================] - 0s 490us/step - loss: 78.7411 - val_loss: 92.6620\n","Epoch 962/1000\n","889/889 [==============================] - 0s 486us/step - loss: 78.9798 - val_loss: 93.1646\n","Epoch 963/1000\n","889/889 [==============================] - 0s 517us/step - loss: 77.9104 - val_loss: 93.6849\n","Epoch 964/1000\n","889/889 [==============================] - 0s 492us/step - loss: 80.7590 - val_loss: 94.2748\n","Epoch 965/1000\n","889/889 [==============================] - 0s 499us/step - loss: 77.6914 - val_loss: 96.7109\n","Epoch 966/1000\n","889/889 [==============================] - 0s 486us/step - loss: 77.9137 - val_loss: 92.3109\n","Epoch 967/1000\n","889/889 [==============================] - 0s 512us/step - loss: 75.8967 - val_loss: 95.1921\n","Epoch 968/1000\n","889/889 [==============================] - 0s 493us/step - loss: 75.2943 - val_loss: 94.8752\n","Epoch 969/1000\n","889/889 [==============================] - 0s 496us/step - loss: 76.0799 - val_loss: 92.8695\n","Epoch 970/1000\n","889/889 [==============================] - 0s 508us/step - loss: 74.2462 - val_loss: 94.4258\n","Epoch 971/1000\n","889/889 [==============================] - 0s 502us/step - loss: 74.4056 - val_loss: 95.4367\n","Epoch 972/1000\n","889/889 [==============================] - 0s 514us/step - loss: 73.3084 - val_loss: 93.1564\n","Epoch 973/1000\n","889/889 [==============================] - 0s 502us/step - loss: 73.6081 - val_loss: 94.4380\n","Epoch 974/1000\n","889/889 [==============================] - 0s 516us/step - loss: 73.4057 - val_loss: 97.0730\n","Epoch 975/1000\n","889/889 [==============================] - 0s 502us/step - loss: 72.1382 - val_loss: 95.1721\n","Epoch 976/1000\n","889/889 [==============================] - 0s 518us/step - loss: 72.1335 - val_loss: 92.6730\n","Epoch 977/1000\n","889/889 [==============================] - 0s 512us/step - loss: 73.1593 - val_loss: 94.2532\n","Epoch 978/1000\n","889/889 [==============================] - 0s 500us/step - loss: 72.3199 - val_loss: 94.4537\n","Epoch 979/1000\n","889/889 [==============================] - 0s 504us/step - loss: 72.8326 - val_loss: 94.6933\n","Epoch 980/1000\n","889/889 [==============================] - 0s 503us/step - loss: 71.6029 - val_loss: 95.9260\n","Epoch 981/1000\n","889/889 [==============================] - 0s 506us/step - loss: 71.7621 - val_loss: 97.5871\n","Epoch 982/1000\n","889/889 [==============================] - 0s 507us/step - loss: 71.6918 - val_loss: 95.0780\n","Epoch 983/1000\n","889/889 [==============================] - 0s 514us/step - loss: 71.4364 - val_loss: 94.2216\n","Epoch 984/1000\n","889/889 [==============================] - 0s 506us/step - loss: 71.1559 - val_loss: 95.5736\n","Epoch 985/1000\n","889/889 [==============================] - 0s 502us/step - loss: 71.7284 - val_loss: 92.8906\n","Epoch 986/1000\n","889/889 [==============================] - 0s 506us/step - loss: 71.8572 - val_loss: 95.7164\n","Epoch 987/1000\n","889/889 [==============================] - 0s 504us/step - loss: 72.0387 - val_loss: 94.4460\n","Epoch 988/1000\n","889/889 [==============================] - 0s 506us/step - loss: 72.2835 - val_loss: 94.7831\n","Epoch 989/1000\n","889/889 [==============================] - 0s 499us/step - loss: 72.2891 - val_loss: 96.4338\n","Epoch 990/1000\n","889/889 [==============================] - 0s 509us/step - loss: 71.5917 - val_loss: 95.4633\n","Epoch 991/1000\n","889/889 [==============================] - 0s 494us/step - loss: 71.4525 - val_loss: 94.1828\n","Epoch 992/1000\n","889/889 [==============================] - 0s 517us/step - loss: 71.1683 - val_loss: 95.9805\n","Epoch 993/1000\n","889/889 [==============================] - 0s 494us/step - loss: 71.1372 - val_loss: 96.0451\n","Epoch 994/1000\n","889/889 [==============================] - 0s 500us/step - loss: 71.2966 - val_loss: 95.5130\n","Epoch 995/1000\n","889/889 [==============================] - 0s 501us/step - loss: 74.7261 - val_loss: 94.2146\n","Epoch 996/1000\n","889/889 [==============================] - 0s 486us/step - loss: 72.4249 - val_loss: 94.9716\n","Epoch 997/1000\n","889/889 [==============================] - 0s 495us/step - loss: 73.1311 - val_loss: 95.2265\n","Epoch 998/1000\n","889/889 [==============================] - 0s 489us/step - loss: 72.5294 - val_loss: 93.3942\n","Epoch 999/1000\n","889/889 [==============================] - 0s 510us/step - loss: 72.3800 - val_loss: 96.3801\n","Epoch 1000/1000\n","889/889 [==============================] - 0s 491us/step - loss: 71.4879 - val_loss: 96.5034\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.History at 0x7f2ca6abc828>"]},"metadata":{"tags":[]},"execution_count":61}]},{"metadata":{"id":"rdDAQwvoVrDa","colab_type":"code","colab":{}},"cell_type":"code","source":["\"\"\"\n","model = models.Sequential()\n","\n","model.add(layers.Masking(-100, name=\"input\", input_shape=(None, len(ts_cols))))\n","model.add(layers.BatchNormalization())\n","model.add(layers.LSTM(128, return_sequences=True, name='lstm1'))\n","model.add(layers.Dropout(0.1))\n","model.add(layers.TimeDistributed(layers.Dense(1, name='output')))\n","\n","print(model.summary())\n","\n","model.compile(optimizers.Adam(), loss=custom_mape_exp)\n","\"\"\""],"execution_count":0,"outputs":[]},{"metadata":{"id":"9mrEjt_3Fo7V","colab_type":"code","colab":{}},"cell_type":"code","source":["\"\"\"\n","from keras.layers.core import Permute\n","\n","def attention_3d_block(inputs):\n","    # inputs.shape = (batch_size, time_steps, input_dim)\n","    a = Permute((2, 1))(inputs)\n","    a = Reshape((25, 250))(a)\n","    a = layers.Dense(25, activation='softmax')(inputs)\n","    output_attention_mul = layers.merge.multiply([inputs, a], name='attention_mul')\n","    return output_attention_mul\n","\n","inputs = layers.Input(shape=(250, len(ts_cols)))\n","attention_mul = attention_3d_block(inputs)\n","mask = layers.Masking(-100)(attention_mul)\n","lstm_out = layers.LSTM(128, return_sequences=False)(mask)\n","dense1 = layers.Dense(64, activation='relu')(lstm_out)\n","dense2 = layers.Dense(32, activation='relu')(dense1)\n","output = layers.Dense(1)(dense2)\n","model = models.Model(input=[inputs], output=output)\n","\n","print(model.summary())\n","\n","model.compile(optimizers.Adam(), loss=custom_mape_exp)\n","\"\"\""],"execution_count":0,"outputs":[]},{"metadata":{"id":"xbRw-0JfQ-iB","colab_type":"code","colab":{}},"cell_type":"code","source":["#(4272, 250, 25) (474, 250, 25)  #Reshape the (?, 12,1000) tensor to (?, 1000, 12, 1) tensor.\n","\n","#time_series_reshaped = np.reshape(time_series, (4272, 25, 250, 1))\n","#time_series_val_reshaped = np.reshape(val_time_series, (474, 25, 250, 1))"],"execution_count":0,"outputs":[]},{"metadata":{"id":"V_XuwkaZpves","colab_type":"code","colab":{}},"cell_type":"code","source":["model.fit(time_series, train_labels, batch_size=64, epochs=1000, validation_data=(val_time_series, val_labels))"],"execution_count":0,"outputs":[]},{"metadata":{"id":"X8SrtSpupwlR","colab_type":"code","colab":{}},"cell_type":"code","source":["\"\"\"\n","{15: 0.25369314638650514, 3: 0.3485206977395646, 7: 0.27274180323993563, \n"," 1: 0.3258186511871589, 8: 0.49481063651450297, 2: 0.3888194424409063, \n"," 6: 0.28262367909221875, 14: 0.28390152064193996}\n","Expected LB MAPE = 0.31390297272100504\n","\"\"\""],"execution_count":0,"outputs":[]},{"metadata":{"id":"SVvVClohwfGU","colab_type":"code","colab":{}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]}]}